# ============================================================
# í—¬ìŠ¤ì¼€ì–´ AI ì½˜í…ì¸  ì œì‘ ì•± (Streamlit + GPT-5 Mini / SDXL ë¡œì»¬)
# ============================================================

import os
import streamlit as st
from openai import OpenAI
from diffusers import StableDiffusionXLPipeline
import torch
from io import BytesIO

# ============================================================
# ğŸŒ í™˜ê²½ ë³€ìˆ˜ ë° AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# ============================================================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL_GPT_MINI = "gpt-5-mini"

openai_client = None
if OPENAI_API_KEY:
    try:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
    except Exception as e:
        st.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
else:
    st.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ============================================================
# ğŸ–¥ Streamlit í˜ì´ì§€ ì„¤ì •
# ============================================================

st.set_page_config(page_title="ğŸ’ª í—¬ìŠ¤ì¼€ì–´ AI ì½˜í…ì¸  ì œì‘", layout="wide")
st.sidebar.title("ë©”ë‰´")
menu = st.sidebar.radio(
    "í˜ì´ì§€ ì„ íƒ",
    ["ğŸ“ í™ë³´ ë¬¸êµ¬+í•´ì‹œíƒœê·¸ ìƒì„±", "ğŸ–¼ ì¸ìŠ¤íƒ€ê·¸ë¨ ì´ë¯¸ì§€ ìƒì„±", "ğŸ–¼ï¸ ì´ë¯¸ì§€ í¸ì§‘/í•©ì„±"],
)

# ============================================================
# ğŸ§© ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================

def validate_inputs(service_name, features):
    if not service_name.strip() or not features.strip():
        st.warning("âš ï¸ ì„œë¹„ìŠ¤ ì´ë¦„ê³¼ í•µì‹¬ íŠ¹ì§•ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return False
    return True

def parse_output(output):
    captions, hashtags = [], ""
    try:
        if "ë¬¸êµ¬:" in output and "í•´ì‹œíƒœê·¸:" in output:
            parts = output.split("í•´ì‹œíƒœê·¸:")
            caption_part = parts[0].replace("ë¬¸êµ¬:", "").strip()
            hashtags = parts[1].strip()
            for line in caption_part.split("\n"):
                if line.strip() and (line[0].isdigit() and "." in line):
                    captions.append(line.split(".", 1)[1].strip())
                elif line.strip() and not line.startswith("ë¬¸êµ¬:"):
                    captions.append(line.strip())
    except Exception:
        return [output], ""
    return captions, hashtags

def generate_caption_and_hashtags(client, model, tone, info, hashtag_count=15):
    prompt = f"""
ë‹¹ì‹ ì€ í—¬ìŠ¤ì¼€ì–´ ì†Œìƒê³µì¸ì„ ìœ„í•œ ì „ë¬¸ ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ì— ìµœì í™”ëœ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

ìš”ì²­:
1. ì¸ìŠ¤íƒ€ê·¸ë¨ í™ë³´ ë¬¸êµ¬ 3ê°œ ì‘ì„±
    - ê° ë¬¸êµ¬: í›„í‚¹ â†’ í•µì‹¬ ë©”ì‹œì§€ â†’ CTA
    - ì´ëª¨í‹°ì½˜ ì‚¬ìš©
    - ë¬¸ì²´ ìŠ¤íƒ€ì¼: {tone}
2. í•´ì‹œíƒœê·¸ {hashtag_count}ê°œ ì¶”ì²œ (ì¤‘ë³µ ì œê±°)

[ì •ë³´]
ì„œë¹„ìŠ¤ ì¢…ë¥˜: {info['service_type']}
ì„œë¹„ìŠ¤ëª…: {info['service_name']}
í•µì‹¬ íŠ¹ì§•: {info['features']}
ì§€ì—­: {info['location']}
ì´ë²¤íŠ¸: {info['event_info']}

ì¶œë ¥ í˜•ì‹:
ë¬¸êµ¬:
1. [ë¬¸êµ¬1]
2. [ë¬¸êµ¬2]
3. [ë¬¸êµ¬3]

í•´ì‹œíƒœê·¸:
#[íƒœê·¸1] #[íƒœê·¸2] ... #[íƒœê·¸N]
"""
    try:
        response = client.responses.create(model=model, input=prompt, reasoning={"effort":"minimal"})
        return response.output_text.strip()
    except Exception as e:
        st.error(f"GPT-5 Mini í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return f"ë¬¸êµ¬:\n1. [API ì˜¤ë¥˜]\ní•´ì‹œíƒœê·¸:\n#[APIì˜¤ë¥˜]"

# ============================================================
# ğŸ–¼ ë¡œì»¬ SDXL ì´ˆê¸°í™” & ì´ë¯¸ì§€ ìƒì„±
# ============================================================

pipe = None
def init_local_sdxl(model_id="stabilityai/stable-diffusion-xl-base-1.0"):
    global pipe
    if pipe is None:
        pipe = StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
        pipe = pipe.to("cuda")  # GPU ì—†ìœ¼ë©´ "cpu"
    return pipe

def generate_image_local(prompt, width=1024, height=1024, steps=30):
    global pipe
    if pipe is None:
        pipe = init_local_sdxl()
    negative_prompt = "low quality, blurry, text, watermark, distorted"
    result = pipe(prompt=prompt, negative_prompt=negative_prompt, width=width, height=height, num_inference_steps=steps)
    image = result.images[0]
    buf = BytesIO()
    image.save(buf, format="PNG")
    buf.seek(0)
    return buf

def caption_to_image_prompt(caption, style="Instagram banner"):
    return f"{caption}, {style}, vibrant, professional, motivational"

# ============================================================
# ğŸ“ í˜ì´ì§€ 1: í™ë³´ ë¬¸êµ¬ + í•´ì‹œíƒœê·¸
# ============================================================

if menu == "ğŸ“ í™ë³´ ë¬¸êµ¬+í•´ì‹œíƒœê·¸ ìƒì„±":
    st.title("ğŸ“ í™ë³´ ë¬¸êµ¬ & í•´ì‹œíƒœê·¸ ìƒì„±")
    if openai_client:
        with st.form("content_form"):
            service_name = st.text_input("ì œí’ˆ/í´ë˜ìŠ¤ ì´ë¦„")
            features = st.text_area("í•µì‹¬ íŠ¹ì§• ë° ì¥ì ")
            tone = st.selectbox("í†¤ ì„ íƒ", ["ì¹œê·¼í•˜ê³  ë™ê¸°ë¶€ì—¬","ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê°","ì¬ë¯¸ìˆê³  íŠ¸ë Œë””","ì°¨ë¶„í•˜ê³  ê°ì„±ì "])
            submitted = st.form_submit_button("âœ¨ ë¬¸êµ¬+í•´ì‹œíƒœê·¸ ìƒì„±")

        if submitted and validate_inputs(service_name, features):
            info = {"service_type":"í—¬ìŠ¤/í”¼íŠ¸ë‹ˆìŠ¤","service_name":service_name,"features":features,"location":"ì „êµ­/ì˜¨ë¼ì¸","event_info":"ì—†ìŒ"}
            output = generate_caption_and_hashtags(openai_client, MODEL_GPT_MINI, tone, info, 15)
            captions, hashtags = parse_output(output)
            st.session_state["captions"] = captions
            st.session_state["hashtags"] = hashtags

        if "captions" in st.session_state:
            st.markdown("### ğŸ’¬ ìƒì„±ëœ ë¬¸êµ¬")
            for i, caption in enumerate(st.session_state["captions"]):
                st.radio(f"ë¬¸êµ¬ ì„ íƒ {i+1}", st.session_state["captions"], key=f"selected_caption_{i}")
            st.markdown("### ğŸ”– ì¶”ì²œ í•´ì‹œíƒœê·¸")
            st.code(st.session_state["hashtags"])

# ============================================================
# ğŸ–¼ í˜ì´ì§€ 2: ë¬¸êµ¬ ê¸°ë°˜ ì´ë¯¸ì§€ 3ë²„ì „ ìƒì„±
# ============================================================

elif menu == "ğŸ–¼ ì¸ìŠ¤íƒ€ê·¸ë¨ ì´ë¯¸ì§€ ìƒì„±":
    st.title("ğŸ–¼ ë¬¸êµ¬ ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„± (3ê°€ì§€ ë²„ì „)")
    if "captions" not in st.session_state:
        st.warning("âš ï¸ í˜ì´ì§€1ì—ì„œ ë¬¸êµ¬ë¥¼ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        selected_caption = st.selectbox("ì´ë¯¸ì§€ì— ë°˜ì˜í•  ë¬¸êµ¬ ì„ íƒ", st.session_state["captions"])
        image_size = st.selectbox("ì´ë¯¸ì§€ í¬ê¸°", ["1024x1024","1792x1024","1024x1792"])
        submitted = st.button("ğŸ–¼ 3ê°€ì§€ ë²„ì „ ìƒì„±")

        if submitted:
            width, height = map(int, image_size.split("x"))
            st.session_state["generated_images"] = []
            st.info("â³ 3ê°€ì§€ ë²„ì „ ìƒì„± ì¤‘...")
            for i in range(3):
                version_prompt = caption_to_image_prompt(f"{selected_caption} (version {i+1})")
                image_bytes = generate_image_local(version_prompt, width=width, height=height)
                st.session_state["generated_images"].append({"prompt": version_prompt, "bytes": image_bytes})

            st.success("âœ… 3ê°€ì§€ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
            for idx, img_data in enumerate(st.session_state["generated_images"]):
                st.image(img_data["bytes"], caption=f"ë²„ì „ {idx+1}: {img_data['prompt']}", use_column_width=True)
                st.download_button(f"ë²„ì „ {idx+1} ë‹¤ìš´ë¡œë“œ", img_data["bytes"], f"instagram_banner_v{idx+1}.png","image/png")

# ============================================================
# ğŸ–¼ í˜ì´ì§€ 3: ì´ë¯¸ì§€ í¸ì§‘/í•©ì„± (ë¡œì»¬ SDXL)
# ============================================================

elif menu == "ğŸ–¼ï¸ ì´ë¯¸ì§€ í¸ì§‘/í•©ì„±":
    st.title("ğŸ–¼ï¸ ì´ë¯¸ì§€ í¸ì§‘ / í•©ì„±")
    uploaded_file = st.file_uploader("ì—…ë¡œë“œ ì´ë¯¸ì§€ (ì—†ìœ¼ë©´ í˜ì´ì§€2 ì„ íƒ ì´ë¯¸ì§€ ì‚¬ìš©)", type=["png","jpg","jpeg"])
    preloaded_image = st.session_state.get("generated_images", [None])[0]
    image_bytes = uploaded_file.getvalue() if uploaded_file else preloaded_image

    if image_bytes and "captions" in st.session_state:
        selected_caption = st.selectbox("í¸ì§‘ì— ë°˜ì˜í•  ë¬¸êµ¬ ì„ íƒ", st.session_state["captions"])
        edit_prompt = st.text_area("ì¶”ê°€ í¸ì§‘ ì§€ì‹œ (ì„ íƒ)")
        output_size = st.selectbox("ì¶œë ¥ ì´ë¯¸ì§€ í¬ê¸°", ["1024x1024","1792x1024","1024x1792"])
        submitted = st.button("âœ¨ í•©ì„± ì´ë¯¸ì§€ ìƒì„±")

        if submitted:
            width, height = map(int, output_size.split('x'))
            final_prompt = caption_to_image_prompt(selected_caption)
            if edit_prompt:
                final_prompt += f", {edit_prompt}"
            with st.spinner("í•©ì„±/í¸ì§‘ ì¤‘... â³"):
                edited_image_bytes = generate_image_local(final_prompt, width=width, height=height)
                st.image(edited_image_bytes, caption=final_prompt, use_column_width=True)
                st.download_button("í•©ì„± ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ", edited_image_bytes, "edited_image.png","image/png")

