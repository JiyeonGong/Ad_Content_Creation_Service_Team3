# C:\Users\devuser\Codeit\Ad_Content_Creation_Service_Team3\src\healthcare\streamlit.py
# ============================================================
# ğŸ’ª í—¬ìŠ¤ì¼€ì–´ AI ì½˜í…ì¸  ì œì‘ ì•± (Streamlit + GPT-5 Mini / SDXL ë¡œì»¬)
# ì—°ê²° ëª¨ë“œ ON/OFF ì§€ì›
# ìºì‹œ ê²½ë¡œ í†µí•© ì ìš© (Streamlit + Hugging Face)
# ============================================================

import os
import re
import streamlit as st
from openai import OpenAI
from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
import torch
from io import BytesIO
from PIL import Image

# ============================================================
# ğŸŒ í”„ë¡œì íŠ¸ ê¸°ë°˜ ìºì‹œ ê²½ë¡œ ì„¤ì •
# ============================================================

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ (src í´ë” ê¸°ì¤€)
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
cache_root = os.path.join(project_root, "cache")
os.makedirs(cache_root, exist_ok=True)

# Streamlit ìºì‹œ (ğŸš« 'global.cacheDir' ì˜µì…˜ì€ ì§€ì›ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°)
# st.set_option("global.cacheDir", streamlit_cache_dir)
# Streamlit ìºì‹œ íŒŒì¼ì€ ê¸°ë³¸ ê²½ë¡œ (~/.streamlit/cache)ì— ì €ì¥ë¨.

# Hugging Face ëª¨ë¸ ìºì‹œ
hf_cache_dir = os.path.join(cache_root, "hf_models")
os.makedirs(hf_cache_dir, exist_ok=True)

# Streamlit ìºì‹œ ê²½ë¡œë¥¼ ì§€ì •í•˜ëŠ” ì½”ë“œë¥¼ ì œê±°
# st.sidebar.info(f"Streamlit ìºì‹œ: ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©\n HF ëª¨ë¸ ìºì‹œ: {hf_cache_dir}")


# ============================================================
# ğŸŒ± .env ìë™ ë¡œë”©
# ============================================================
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ .env ê²½ë¡œ ì§€ì •
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
dotenv_path = os.path.join(project_root, ".env")
load_dotenv(dotenv_path)

# ============================================================
# ğŸŒ í™˜ê²½ ë³€ìˆ˜ ë° AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# ============================================================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL_GPT_MINI = "gpt-5-mini"

openai_client = None
if OPENAI_API_KEY:
    try:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
    except Exception as e:
        st.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
else:
    st.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ============================================================
# ğŸ–¥ Streamlit í˜ì´ì§€ ì„¤ì •
# ============================================================

st.set_page_config(page_title="ğŸ’ª í—¬ìŠ¤ì¼€ì–´ AI ì½˜í…ì¸  ì œì‘", layout="wide")
st.sidebar.title("ë©”ë‰´")

menu = st.sidebar.radio(
    "í˜ì´ì§€ ì„ íƒ",
    ["ğŸ“ í™ë³´ ë¬¸êµ¬+í•´ì‹œíƒœê·¸ ìƒì„±", "ğŸ–¼ ì¸ìŠ¤íƒ€ê·¸ë¨ ì´ë¯¸ì§€ ìƒì„±", "ğŸ–¼ï¸ ì´ë¯¸ì§€ í¸ì§‘/í•©ì„±"],
)

connect_mode = st.sidebar.checkbox("ğŸ”— í˜ì´ì§€ ì—°ê²° ëª¨ë“œ", value=True)
st.sidebar.info("ì—°ê²° ëª¨ë“œ ON: í˜ì´ì§€1ì—ì„œ ìƒì„±ëœ ë¬¸êµ¬ë¥¼ ìë™ìœ¼ë¡œ í˜ì´ì§€2/3ì— ì‚¬ìš©\n"
                "OFF: ê° í˜ì´ì§€ ë…ë¦½ ì…ë ¥ ì‚¬ìš©")

# ============================================================
# ğŸ§© ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================

def validate_inputs(service_name, features):
    if not service_name.strip() or not features.strip():
        st.warning("âš ï¸ ì„œë¹„ìŠ¤ ì´ë¦„ê³¼ í•µì‹¬ íŠ¹ì§•ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return False
    return True

def parse_output(output):
    captions, hashtags = [], ""
    try:
        m = re.search(r"ë¬¸êµ¬:(.*?)í•´ì‹œíƒœê·¸:(.*)", output, re.S)
        if m:
            caption_text = m.group(1).strip()
            hashtags = m.group(2).strip()
            captions = [line.split(".",1)[1].strip() if "." in line else line.strip()
                         for line in caption_text.split("\n") if line.strip()]
        else:
            captions = [output]
    except Exception:
        captions = [output]
    return captions, hashtags

@st.cache_data(show_spinner="AIê°€ í™ë³´ ë¬¸êµ¬ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘... â³")
def generate_caption_and_hashtags(client, model, tone, info, hashtag_count=15):
    prompt = f"""
ë‹¹ì‹ ì€ í—¬ìŠ¤ì¼€ì–´ ì†Œìƒê³µì¸ì„ ìœ„í•œ ì „ë¬¸ ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ì— ìµœì í™”ëœ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

ìš”ì²­:
1. ì¸ìŠ¤íƒ€ê·¸ë¨ í™ë³´ ë¬¸êµ¬ 3ê°œ ì‘ì„±
    - ê° ë¬¸êµ¬: í›„í‚¹ â†’ í•µì‹¬ ë©”ì‹œì§€ â†’ CTA
    - ì´ëª¨í‹°ì½˜ ì‚¬ìš©
    - ë¬¸ì²´ ìŠ¤íƒ€ì¼: {tone}
2. í•´ì‹œíƒœê·¸ {hashtag_count}ê°œ ì¶”ì²œ (ì¤‘ë³µ ì œê±°)

[ì •ë³´]
ì„œë¹„ìŠ¤ ì¢…ë¥˜: {info['service_type']}
ì„œë¹„ìŠ¤ëª…: {info['service_name']}
í•µì‹¬ íŠ¹ì§•: {info['features']}
ì§€ì—­: {info['location']}
ì´ë²¤íŠ¸: {info['event_info']}

ì¶œë ¥ í˜•ì‹:
ë¬¸êµ¬:
1. [ë¬¸êµ¬1]
2. [ë¬¸êµ¬2]
3. [ë¬¸êµ¬3]

í•´ì‹œíƒœê·¸:
#[íƒœê·¸1] #[íƒœê·¸2] ... #[íƒœê·¸N]
"""
    try:
        response = client.responses.create(
            model=model,
            input=prompt,
            reasoning={"effort":"minimal"},
            max_output_tokens=512, 
        )
        return response.output_text.strip()
    except Exception as e:
        st.error(f"GPT-5 Mini í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return f"ë¬¸êµ¬:\n1. [API ì˜¤ë¥˜]\ní•´ì‹œíƒœê·¸:\n#[APIì˜¤ë¥˜]"

# ============================================================
# ğŸ–¼ SDXL ì´ˆê¸°í™” ë° ì´ë¯¸ì§€ ìƒì„±
# ============================================================

@st.cache_resource(show_spinner="SDXL T2I ëª¨ë¸ ë¡œë”© ì¤‘...")
def init_local_sdxl_t2i(model_id="stabilityai/stable-diffusion-xl-base-1.0"):
    if not torch.cuda.is_available():
        st.warning("âš ï¸ GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ìƒì„±ì´ ë§¤ìš° ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    pipe = StableDiffusionXLPipeline.from_pretrained(
        model_id,
        cache_dir=hf_cache_dir,  # HF ëª¨ë¸ ìºì‹œ ê²½ë¡œ ì§€ì •
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
    )
    device = "cuda" if torch.cuda.is_available() else "cpu"
    return pipe.to(device)

@st.cache_resource(show_spinner="SDXL I2I ëª¨ë¸ ë¡œë”© ì¤‘...")
def init_local_sdxl_i2i(model_id="stabilityai/stable-diffusion-xl-base-1.0"):
    if not torch.cuda.is_available():
        st.warning("âš ï¸ GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ìƒì„±ì´ ë§¤ìš° ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(
        model_id,
        cache_dir=hf_cache_dir,  # HF ëª¨ë¸ ìºì‹œ ê²½ë¡œ ì§€ì •
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
    )
    device = "cuda" if torch.cuda.is_available() else "cpu"
    return pipe.to(device)

@st.cache_data(show_spinner=False)
def generate_image_local(prompt, width=1024, height=1024, steps=30):
    pipe = init_local_sdxl_t2i()
    negative_prompt = "low quality, blurry, text, watermark, distorted"
    result = pipe(prompt=prompt, negative_prompt=negative_prompt, width=width, height=height, num_inference_steps=steps)
    image = result.images[0]
    buf = BytesIO()
    image.save(buf, format="PNG")
    buf.seek(0)
    return buf

@st.cache_data(show_spinner=False)
def generate_image_i2i_local(input_image_bytes, prompt, strength=0.75, width=1024, height=1024, steps=30):
    pipe = init_local_sdxl_i2i()
    negative_prompt = "low quality, blurry, text, watermark, distorted"
    input_image = Image.open(BytesIO(input_image_bytes)).convert("RGB").resize((width, height))
    result = pipe(
        prompt=prompt, 
        image=input_image,
        strength=strength,
        negative_prompt=negative_prompt, 
        num_inference_steps=steps
    )
    image = result.images[0]
    buf = BytesIO()
    image.save(buf, format="PNG")
    buf.seek(0)
    return buf

def caption_to_image_prompt(caption, style="Instagram banner"):
    return f"{caption}, {style}, vibrant, professional, motivational"

# ============================================================
# ğŸ”„ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ============================================================

if not connect_mode:
    st.cache_data.clear() 
    for key in ["captions","hashtags","generated_images","selected_caption"]:
        if key in st.session_state:
            del st.session_state[key]

# ============================================================
# ğŸ“ í˜ì´ì§€ 1: í™ë³´ ë¬¸êµ¬ + í•´ì‹œíƒœê·¸
# ============================================================

if menu == "ğŸ“ í™ë³´ ë¬¸êµ¬+í•´ì‹œíƒœê·¸ ìƒì„±":
    st.title("ğŸ“ í™ë³´ ë¬¸êµ¬ & í•´ì‹œíƒœê·¸ ìƒì„±")
    
    if not openai_client:
        st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        with st.form("content_form"):
            
            # ğŸ‘‡ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì¶”ê°€ëœ ì…ë ¥ í•„ë“œ
            service_type = st.selectbox(
                "ì„œë¹„ìŠ¤ ì¢…ë¥˜",
                ["í—¬ìŠ¤ì¥", "PT (ê°œì¸ íŠ¸ë ˆì´ë‹)", "ìš”ê°€/í•„ë¼í…ŒìŠ¤", "ê±´ê°• ì‹í’ˆ/ë³´ì¡°ì œ", "ê¸°íƒ€"],
            )
            location = st.text_input("ì§€ì—­", placeholder="ì˜ˆ: ê°•ë‚¨, ë§ˆí¬êµ¬, ì˜¨ë¼ì¸")
            # ğŸ‘† ì¶”ê°€ëœ ì…ë ¥ í•„ë“œ

            service_name = st.text_input("ì œí’ˆ/í´ë˜ìŠ¤ ì´ë¦„", placeholder="ì˜ˆ: 30ì¼ ë‹¤ì´ì–´íŠ¸ ì±Œë¦°ì§€")
            features = st.text_area("í•µì‹¬ íŠ¹ì§• ë° ì¥ì ", placeholder="ì˜ˆ: ì „ë¬¸ PTì™€ í•¨ê»˜í•˜ëŠ” ë§ì¶¤í˜• ìš´ë™, ì˜ì–‘ ê´€ë¦¬ í¬í•¨")
            tone = st.selectbox("í†¤ ì„ íƒ", ["ì¹œê·¼í•˜ê³  ë™ê¸°ë¶€ì—¬","ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê°","ì¬ë¯¸ìˆê³  íŠ¸ë Œë””","ì°¨ë¶„í•˜ê³  ê°ì„±ì "])
            submitted = st.form_submit_button("âœ¨ ë¬¸êµ¬+í•´ì‹œíƒœê·¸ ìƒì„±")

        if submitted:
            # `location`ê³¼ `service_name`, `features`ëŠ” GPT í”„ë¡¬í”„íŠ¸ì— í•„ìˆ˜ì ì´ë¯€ë¡œ, 
            # `location`ì˜ ë¹ˆ ê°’ ì²´í¬ë¥¼ `validate_inputs`ì— í¬í•¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
            if validate_inputs(service_name, features) and location.strip(): # ì§€ì—­ ì •ë³´ê°€ ì¶”ê°€ë¨
                
                info = {
                    "service_type": service_type, # ğŸ‘ˆ ìƒˆë¡œìš´ ì •ë³´ í¬í•¨
                    "service_name": service_name,
                    "features": features,
                    "location": location,       # ğŸ‘ˆ ìƒˆë¡œìš´ ì •ë³´ í¬í•¨
                    "event_info":"ì—†ìŒ"
                }
                
                output = generate_caption_and_hashtags(openai_client, MODEL_GPT_MINI, tone, info, 15)
                captions, hashtags = parse_output(output)
                st.session_state["captions"] = captions
                st.session_state["hashtags"] = hashtags
            else:
                 st.warning("âš ï¸ ì„œë¹„ìŠ¤ ì´ë¦„, í•µì‹¬ íŠ¹ì§•, **ì§€ì—­**ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")


        # ìƒì„±ëœ ë¬¸êµ¬ í‘œì‹œ ë° ì„ íƒ (ì´í•˜ ë™ì¼)
        if "captions" in st.session_state and st.session_state["captions"]:
            # ... (ì´í•˜ ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
            st.markdown("### ğŸ’¬ ìƒì„±ëœ ë¬¸êµ¬")
            for i, caption in enumerate(st.session_state["captions"], 1):
                st.write(f"**{i}.** {caption}")
            
            st.markdown("---")
            selected_idx = st.radio(
                "ë‹¤ìŒ í˜ì´ì§€ì—ì„œ ì‚¬ìš©í•  ë¬¸êµ¬ ì„ íƒ:", 
                range(len(st.session_state["captions"])),
                format_func=lambda x: f"ë¬¸êµ¬ {x+1}",
                key="caption_selector"
            )
            st.session_state["selected_caption"] = st.session_state["captions"][selected_idx]
            
            st.success(f"âœ… ì„ íƒëœ ë¬¸êµ¬: {st.session_state['selected_caption'][:50]}...")
            
            st.markdown("### ğŸ”– ì¶”ì²œ í•´ì‹œíƒœê·¸")
            st.code(st.session_state["hashtags"], language="")

# ============================================================
# ğŸ–¼ í˜ì´ì§€ 2: ë¬¸êµ¬ ê¸°ë°˜ ì´ë¯¸ì§€ 3ë²„ì „ ìƒì„±
# ============================================================

elif menu == "ğŸ–¼ ì¸ìŠ¤íƒ€ê·¸ë¨ ì´ë¯¸ì§€ ìƒì„±":
    st.title("ğŸ–¼ ë¬¸êµ¬ ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„± (3ê°€ì§€ ë²„ì „)")
    
    # ì—°ê²° ëª¨ë“œì¼ ë•Œ í˜ì´ì§€1 ë¬¸êµ¬ ì‚¬ìš© ê°€ëŠ¥
    if connect_mode and "selected_caption" in st.session_state:
        st.info(f"ğŸ”— ì—°ê²° ëª¨ë“œ: í˜ì´ì§€1ì—ì„œ ì„ íƒí•œ ë¬¸êµ¬ ì‚¬ìš©\n\n**ì„ íƒëœ ë¬¸êµ¬:** {st.session_state['selected_caption']}")
        selected_caption = st.session_state["selected_caption"]
    else:
        if connect_mode:
            st.warning("âš ï¸ í˜ì´ì§€1ì—ì„œ ë¬¸êµ¬ë¥¼ ë¨¼ì € ìƒì„±í•˜ê³  ì„ íƒí•˜ì„¸ìš”.")
        selected_caption = st.text_area("ë¬¸êµ¬ ì…ë ¥ (ì—°ê²° ëª¨ë“œ OFF ë˜ëŠ” í˜ì´ì§€1 ë¬¸êµ¬ ì—†ìŒ)", 
                                         placeholder="ì˜ˆ: ğŸ’ª ìƒˆí•´ ëª©í‘œ, ì´ë²ˆì—” ê¼­ ì´ë£¨ì! ì „ë¬¸ PTì™€ í•¨ê»˜í•˜ëŠ” 30ì¼ ë‹¤ì´ì–´íŠ¸ ì±Œë¦°ì§€ ğŸ”¥")
    
    image_size = st.selectbox("ì´ë¯¸ì§€ í¬ê¸°", ["1024x1024","1792x1024","1024x1792"])
    submitted = st.button("ğŸ–¼ 3ê°€ì§€ ë²„ì „ ìƒì„±", type="primary")

    if submitted and selected_caption:
        width, height = map(int, image_size.split("x"))
        st.session_state["generated_images"] = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i in range(3):
            status_text.text(f"â³ ë²„ì „ {i+1}/3 ìƒì„± ì¤‘... (ìºì‹±ë˜ì§€ ì•Šì€ ê²½ìš° ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤)")
            
            # ê° ë²„ì „ë§ˆë‹¤ ì•½ê°„ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸
            version_prompt = caption_to_image_prompt(
                f"{selected_caption} (style variation {i+1})"
            )
            
            try:
                # ğŸŸ¢ generate_image_local í•¨ìˆ˜ê°€ cache_dataë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, 
                # ê°™ì€ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„ ì‹œ ë§¤ìš° ë¹ ë¥´ê²Œ ì´ë¯¸ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
                image_bytes = generate_image_local(version_prompt, width=width, height=height)
                st.session_state["generated_images"].append({
                    "prompt": version_prompt, 
                    "bytes": image_bytes
                })
                progress_bar.progress((i+1)/3)
            except Exception as e:
                st.error(f"ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜ (ë²„ì „ {i+1}): {e}")
                break

        status_text.empty()
        progress_bar.empty()
        
        if st.session_state["generated_images"]:
            st.success(f"âœ… {len(st.session_state['generated_images'])}ê°œ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
            
            cols = st.columns(len(st.session_state["generated_images"]))
            for idx, img_data in enumerate(st.session_state["generated_images"]):
                with cols[idx]:
                    st.image(img_data["bytes"], caption=f"ë²„ì „ {idx+1}", use_container_width=True)
                    st.download_button(
                        f"â¬‡ï¸ ë²„ì „ {idx+1} ë‹¤ìš´ë¡œë“œ", 
                        img_data["bytes"], 
                        f"instagram_banner_v{idx+1}.png",
                        "image/png",
                        key=f"download_{idx}"
                    )

# ============================================================
# ğŸ–¼ í˜ì´ì§€ 3: ì´ë¯¸ì§€ í¸ì§‘/í•©ì„± (I2I ê¸°ëŠ¥ìœ¼ë¡œ ìˆ˜ì •ë¨)
# ============================================================

elif menu == "ğŸ–¼ï¸ ì´ë¯¸ì§€ í¸ì§‘/í•©ì„±":
    st.title("ğŸ–¼ï¸ ì´ë¯¸ì§€ í¸ì§‘ / í•©ì„± (Image-to-Image)")
    
    st.info("ğŸ’¡ ì´ ê¸°ëŠ¥ì€ **ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜**ìœ¼ë¡œ ë¬¸êµ¬ì™€ ì¶”ê°€ ì§€ì‹œë¥¼ ë°˜ì˜í•˜ì—¬ ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    
    # ì´ë¯¸ì§€ ì†ŒìŠ¤ ì„ íƒ
    uploaded_file = st.file_uploader("ì—…ë¡œë“œ ì´ë¯¸ì§€", type=["png","jpg","jpeg"])
    
    # í˜ì´ì§€2ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ í™•ì¸
    preloaded_images = st.session_state.get("generated_images", [])
    
    image_bytes = None
    if uploaded_file:
        image_bytes = uploaded_file.getvalue()
        st.image(image_bytes, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", width=300)
    elif preloaded_images and connect_mode:
        st.info("ğŸ”— ì—°ê²° ëª¨ë“œ: í˜ì´ì§€2ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ ì‚¬ìš©")
        image_idx = st.selectbox("ì‚¬ìš©í•  ì´ë¯¸ì§€ ì„ íƒ", 
                                 range(len(preloaded_images)),
                                 format_func=lambda x: f"ë²„ì „ {x+1}")
        image_bytes = preloaded_images[image_idx]["bytes"].getvalue() # BytesIOì—ì„œ ì‹¤ì œ ë°”ì´íŠ¸ ê°€ì ¸ì˜¤ê¸°
        st.image(image_bytes, caption=f"ì„ íƒëœ ì´ë¯¸ì§€: ë²„ì „ {image_idx+1}", width=300)
    else:
        st.warning("âš ï¸ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ í˜ì´ì§€2ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.")
    
    # ë¬¸êµ¬ ì†ŒìŠ¤ ì„ íƒ
    if connect_mode and "selected_caption" in st.session_state:
        st.info(f"ğŸ”— ì‚¬ìš©í•  ë¬¸êµ¬: {st.session_state['selected_caption']}")
        selected_caption = st.session_state["selected_caption"]
    else:
        selected_caption = st.text_input("í¸ì§‘ì— ë°˜ì˜í•  ë¬¸êµ¬ ì…ë ¥", 
                                         placeholder="ì˜ˆ: ğŸ’ª ìƒˆí•´ ëª©í‘œ, ì´ë²ˆì—” ê¼­ ì´ë£¨ì!")
    
    # I2Iì— í•„ìˆ˜ì ì¸ ë³€í™” ê°•ë„ ìŠ¬ë¼ì´ë” ì¶”ê°€
    denoising_strength = st.slider(
        "âœ¨ ë³€í™” ê°•ë„ (Strength)", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.75, 
        step=0.05,
        help="0.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì›ë³¸ ì´ë¯¸ì§€ ìœ ì§€, 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ í”„ë¡¬í”„íŠ¸ì— ë”°ë¥¸ ìƒˆë¡œìš´ ì´ë¯¸ì§€ ìƒì„±"
    )

    edit_prompt = st.text_area("ì¶”ê°€ í¸ì§‘ ì§€ì‹œ (ì„ íƒ)", 
                                 placeholder="ì˜ˆ: ë” ë°ê³  í™œê¸°ì°¬ ë¶„ìœ„ê¸°ë¡œ, íŒŒë€ìƒ‰ ë°°ê²½ ì¶”ê°€")
    output_size = st.selectbox("ì¶œë ¥ ì´ë¯¸ì§€ í¬ê¸°", ["1024x1024","1792x1024","1024x1792"])
    
    submitted = st.button("âœ¨ í•©ì„±/í¸ì§‘ ì´ë¯¸ì§€ ìƒì„±", type="primary")

    if submitted:
        if not image_bytes:
            st.error("âŒ ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•˜ê±°ë‚˜ í˜ì´ì§€2ì—ì„œ ìƒì„±í•˜ì„¸ìš”.")
        elif not selected_caption:
            st.error("âŒ ë¬¸êµ¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            width, height = map(int, output_size.split('x'))
            
            # ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
            final_prompt = caption_to_image_prompt(selected_caption)
            if edit_prompt:
                final_prompt += f", {edit_prompt}"
            
            with st.spinner("í•©ì„±/í¸ì§‘ ì¤‘... â³ (ìºì‹±ë˜ì§€ ì•Šì€ ê²½ìš° ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤)"):
                try:
                    # ğŸš€ I2I ì „ìš© í•¨ìˆ˜ í˜¸ì¶œ (ì›ë³¸ ì´ë¯¸ì§€ì™€ ë³€í™” ê°•ë„ ì „ë‹¬)
                    edited_image_bytes = generate_image_i2i_local(
                        image_bytes, # ì›ë³¸ ì´ë¯¸ì§€ ë°”ì´íŠ¸ ì „ë‹¬
                        final_prompt, 
                        denoising_strength, # ë³€í™” ê°•ë„ ì „ë‹¬
                        width=width, 
                        height=height
                    )
                    
                    col1, col2 = st.columns(2)
                    
                    # Original Image Display 
                    with col1:
                        st.subheader("ì›ë³¸ ì´ë¯¸ì§€")
                        st.image(image_bytes, use_container_width=True) 

                    # Edited Image Display
                    with col2:
                        st.subheader("í¸ì§‘ëœ ì´ë¯¸ì§€")
                        st.image(edited_image_bytes, caption="I2I ê²°ê³¼", use_container_width=True)
                    
                    st.success("âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
                    st.download_button("â¬‡ï¸ í¸ì§‘ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ", 
                                       edited_image_bytes, 
                                       "edited_image.png",
                                       "image/png")
                except Exception as e:
                    st.error(f"ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}")