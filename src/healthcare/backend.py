# C:\Users\devuser\Codeit\Ad_Content_Creation_Service_Team3\src\healthcare\backend.py
# ============================================================
# âš™ï¸ FastAPI ë°±ì—”ë“œ API ì„œë²„ (AI ì¶”ë¡  ë¡œì§ ë‹´ë‹¹)
# - GPT-5 Mini í˜¸ì¶œ (OpenAI API)
# - SDXL T2I/I2I ë¡œì»¬ ì¶”ë¡  (Diffusers)
# - ì´ë¯¸ì§€ ë°ì´í„°ëŠ” Base64ë¡œ ì¸ì½”ë”©/ë””ì½”ë”©í•˜ì—¬ ì „ì†¡
# ============================================================

import os
import io
import base64
from typing import Dict, Any, List

from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel, Field

# AI ëª¨ë¸ ë° ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from openai import OpenAI
from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
import torch
from PIL import Image
from dotenv import load_dotenv

# ============================================================
# ğŸŒ í™˜ê²½ ì„¤ì • ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# ============================================================

# .env íŒŒì¼ ë¡œë”© (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
load_dotenv(os.path.join(os.path.dirname(__file__), "..", "..", ".env"))

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL_GPT_MINI = "gpt-5-mini"

# Hugging Face ëª¨ë¸ ìºì‹œ ê²½ë¡œ ì„¤ì •
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
hf_cache_dir = os.path.join(project_root, "cache", "hf_models")
os.makedirs(hf_cache_dir, exist_ok=True)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = None
if OPENAI_API_KEY:
    try:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
    except Exception as e:
        print(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
else:
    print("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ GPT ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# SDXL ëª¨ë¸ ì´ˆê¸°í™” (FastAPI ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰)
T2I_PIPE = None
I2I_PIPE = None
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_ID = "stabilityai/stable-diffusion-xl-base-1.0"

def init_sdxl_pipelines():
    """SDXL T2I ë° I2I íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•˜ê³  ì „ì—­ ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤."""
    global T2I_PIPE, I2I_PIPE
    try:
        print(f"SDXL ëª¨ë¸ ë¡œë”© ì¤‘... (Device: {DEVICE}, Cache: {hf_cache_dir})")
        dtype = torch.float16 if torch.cuda.is_available() else torch.float32

        # T2I (Text-to-Image) íŒŒì´í”„ë¼ì¸
        T2I_PIPE = StableDiffusionXLPipeline.from_pretrained(
            MODEL_ID,
            cache_dir=hf_cache_dir,
            torch_dtype=dtype
        ).to(DEVICE)
        
        # I2I (Image-to-Image) íŒŒì´í”„ë¼ì¸
        I2I_PIPE = StableDiffusionXLImg2ImgPipeline.from_pretrained(
            MODEL_ID,
            cache_dir=hf_cache_dir,
            torch_dtype=dtype
        ).to(DEVICE)
        
        print("SDXL ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")
    except Exception as e:
        print(f"SDXL ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        T2I_PIPE = None
        I2I_PIPE = None

# FastAPI ì•± ìƒì„± ë° ëª¨ë¸ ë¡œë”©
app = FastAPI(title="í—¬ìŠ¤ì¼€ì–´ AI ì½˜í…ì¸  API")

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ SDXL ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    init_sdxl_pipelines()

# ============================================================
# ğŸ“œ Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜ (Request/Response ë°ì´í„° êµ¬ì¡°)
# ============================================================

class CaptionRequest(BaseModel):
    """ë¬¸êµ¬ ìƒì„± ìš”ì²­ ë°ì´í„° ëª¨ë¸"""
    service_type: str = Field(..., description="ì„œë¹„ìŠ¤ ì¢…ë¥˜ (ì˜ˆ: í—¬ìŠ¤ì¥)")
    service_name: str = Field(..., description="ì œí’ˆ/í´ë˜ìŠ¤ ì´ë¦„")
    features: str = Field(..., description="í•µì‹¬ íŠ¹ì§• ë° ì¥ì ")
    location: str = Field(..., description="ì§€ì—­")
    tone: str = Field(..., description="ë¬¸ì²´ ìŠ¤íƒ€ì¼")

class CaptionResponse(BaseModel):
    """ë¬¸êµ¬ ìƒì„± ì‘ë‹µ ë°ì´í„° ëª¨ë¸"""
    output_text: str = Field(..., description="GPT-5 Miniê°€ ìƒì„±í•œ ì›ë³¸ í…ìŠ¤íŠ¸")

class T2IRequest(BaseModel):
    """T2I ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ë°ì´í„° ëª¨ë¸"""
    prompt: str = Field(..., description="ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸")
    width: int = 1024
    height: int = 1024
    steps: int = 30

class T2IResponse(BaseModel):
    """T2I ì´ë¯¸ì§€ ìƒì„± ì‘ë‹µ ë°ì´í„° ëª¨ë¸"""
    image_base64: str = Field(..., description="ìƒì„±ëœ ì´ë¯¸ì§€ì˜ Base64 ì¸ì½”ë”© ë¬¸ìì—´ (PNG í˜•ì‹)")

class I2IRequest(BaseModel):
    """I2I ì´ë¯¸ì§€ í¸ì§‘/í•©ì„± ìš”ì²­ ë°ì´í„° ëª¨ë¸"""
    input_image_base64: str = Field(..., description="ì›ë³¸ ì´ë¯¸ì§€ì˜ Base64 ì¸ì½”ë”© ë¬¸ìì—´ (PNG/JPG)")
    prompt: str = Field(..., description="ì´ë¯¸ì§€ í¸ì§‘ í”„ë¡¬í”„íŠ¸")
    strength: float = 0.75
    width: int = 1024
    height: int = 1024
    steps: int = 30

# ============================================================
# ğŸ¯ AI ì¶”ë¡  í•¨ìˆ˜ (ê¸°ì¡´ Streamlit ë¡œì§ì„ API í•¨ìˆ˜ë¡œ ë³€í™˜)
# ============================================================

def generate_caption_core(client, model, tone, info, hashtag_count=15) -> str:
    """GPT-5 Minië¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸êµ¬ ë° í•´ì‹œíƒœê·¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not client:
        raise ValueError("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
    prompt = f"""
ë‹¹ì‹ ì€ í—¬ìŠ¤ì¼€ì–´ ì†Œìƒê³µì¸ì„ ìœ„í•œ ì „ë¬¸ ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ì— ìµœì í™”ëœ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

ìš”ì²­:
1. ì¸ìŠ¤íƒ€ê·¸ë¨ í™ë³´ ë¬¸êµ¬ 3ê°œ ì‘ì„±
    - ê° ë¬¸êµ¬: í›„í‚¹ â†’ í•µì‹¬ ë©”ì‹œì§€ â†’ CTA
    - ì´ëª¨í‹°ì½˜ ì‚¬ìš©
    - ë¬¸ì²´ ìŠ¤íƒ€ì¼: {tone}
2. í•´ì‹œíƒœê·¸ {hashtag_count}ê°œ ì¶”ì²œ (ì¤‘ë³µ ì œê±°)

[ì •ë³´]
ì„œë¹„ìŠ¤ ì¢…ë¥˜: {info['service_type']}
ì„œë¹„ìŠ¤ëª…: {info['service_name']}
í•µì‹¬ íŠ¹ì§•: {info['features']}
ì§€ì—­: {info['location']}
ì´ë²¤íŠ¸: ì—†ìŒ

ì¶œë ¥ í˜•ì‹:
ë¬¸êµ¬:
1. [ë¬¸êµ¬1]
2. [ë¬¸êµ¬2]
3. [ë¬¸êµ¬3]

í•´ì‹œíƒœê·¸:
#[íƒœê·¸1] #[íƒœê·¸2] ... #[íƒœê·¸N]
"""
    try:
        response = client.responses.create(
            model=model,
            input=prompt,
            reasoning={"effort":"minimal"},
            max_output_tokens=512, 
        )
        return response.output_text.strip()
    except Exception as e:
        print(f"GPT-5 Mini í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        raise

def generate_t2i_core(pipe: StableDiffusionXLPipeline, prompt: str, width: int, height: int, steps: int) -> bytes:
    """SDXL T2Ië¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  PNG ë°”ì´íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    negative_prompt = "low quality, blurry, text, watermark, distorted, ugly, tiling, poorly drawn"
    
    result = pipe(
        prompt=prompt, 
        negative_prompt=negative_prompt, 
        width=width, 
        height=height, 
        num_inference_steps=steps,
        guidance_scale=7.5 # ê¸°ë³¸ê°’ ì‚¬ìš©
    )
    image = result.images[0]
    
    # BytesIOë¡œ ë³€í™˜ í›„ ë°˜í™˜
    buf = io.BytesIO()
    image.save(buf, format="PNG")
    return buf.getvalue()

def generate_i2i_core(pipe: StableDiffusionXLImg2ImgPipeline, input_image_bytes: bytes, prompt: str, strength: float, width: int, height: int, steps: int) -> bytes:
    """SDXL I2Ië¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ í¸ì§‘/í•©ì„±í•˜ê³  PNG ë°”ì´íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    negative_prompt = "low quality, blurry, text, watermark, distorted, ugly, tiling, poorly drawn"
    
    # 1. ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì¦ˆ (I2IëŠ” ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°ì— ì˜í–¥ì„ ë°›ìŒ)
    input_image = Image.open(io.BytesIO(input_image_bytes)).convert("RGB").resize((width, height))
    
    # 2. I2I íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    result = pipe(
        prompt=prompt, 
        image=input_image,
        strength=strength,
        negative_prompt=negative_prompt, 
        num_inference_steps=steps,
        guidance_scale=7.5
    )
    image = result.images[0]
    
    # 3. BytesIOë¡œ ë³€í™˜ í›„ ë°˜í™˜
    buf = io.BytesIO()
    image.save(buf, format="PNG")
    return buf.getvalue()


# ============================================================
# ğŸš€ API ì—”ë“œí¬ì¸íŠ¸ ì •ì˜
# ============================================================

@app.post("/api/caption", response_model=CaptionResponse)
async def create_caption(request: CaptionRequest):
    """
    GPT-5 Minië¥¼ ì‚¬ìš©í•˜ì—¬ í™ë³´ ë¬¸êµ¬ì™€ í•´ì‹œíƒœê·¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not openai_client:
        raise HTTPException(status_code=503, detail="GPT-5 Mini ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
    info = {
        "service_type": request.service_type,
        "service_name": request.service_name,
        "features": request.features,
        "location": request.location,
        "event_info": "ì—†ìŒ"
    }

    try:
        output_text = generate_caption_core(openai_client, MODEL_GPT_MINI, request.tone, info)
        return CaptionResponse(output_text=output_text)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¬¸êµ¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


@app.post("/api/generate_t2i", response_model=T2IResponse)
async def generate_t2i_image(request: T2IRequest):
    """
    SDXL T2Ië¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not T2I_PIPE:
        raise HTTPException(status_code=503, detail="SDXL T2I ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    try:
        # ë¹„ë™ê¸°ì ìœ¼ë¡œ GPU ì‘ì—…ì„ ì‹¤í–‰í•˜ëŠ” ê²½ìš° (FastAPIì˜ ê¸°ë³¸ ë™ì‘)
        image_bytes = await app.loop.run_in_executor(
            None, # ê¸°ë³¸ Executor (ì“°ë ˆë“œ í’€)
            generate_t2i_core,
            T2I_PIPE,
            request.prompt,
            request.width,
            request.height,
            request.steps
        )
        
        # Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ JSON ì‘ë‹µìœ¼ë¡œ ë°˜í™˜
        image_base64 = base64.b64encode(image_bytes).decode('utf-8')
        return T2IResponse(image_base64=image_base64)
    except Exception as e:
        # GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë“±ì˜ ì˜¤ë¥˜ ì²˜ë¦¬
        raise HTTPException(status_code=500, detail=f"T2I ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


@app.post("/api/generate_i2i", response_model=T2IResponse) # I2Ië„ T2Iì™€ ë™ì¼í•˜ê²Œ Base64 ì‘ë‹µ
async def generate_i2i_image(request: I2IRequest):
    """
    SDXL I2Ië¥¼ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í¸ì§‘/í•©ì„± ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not I2I_PIPE:
        raise HTTPException(status_code=503, detail="SDXL I2I ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
    try:
        # Base64 ë””ì½”ë”© (ì…ë ¥ ì´ë¯¸ì§€ ë°”ì´íŠ¸)
        input_image_bytes = base64.b64decode(request.input_image_base64)
        
        # ë¹„ë™ê¸°ì ìœ¼ë¡œ GPU ì‘ì—…ì„ ì‹¤í–‰í•˜ëŠ” ê²½ìš°
        image_bytes = await app.loop.run_in_executor(
            None,
            generate_i2i_core,
            I2I_PIPE,
            input_image_bytes,
            request.prompt,
            request.strength,
            request.width,
            request.height,
            request.steps
        )
        
        # Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ JSON ì‘ë‹µìœ¼ë¡œ ë°˜í™˜
        image_base64 = base64.b64encode(image_bytes).decode('utf-8')
        return T2IResponse(image_base64=image_base64)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"I2I ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ìƒíƒœ í™•ì¸ìš© ì—”ë“œí¬ì¸íŠ¸
@app.get("/status")
def get_status():
    return {
        "gpt_ready": openai_client is not None,
        "sdxl_t2i_ready": T2I_PIPE is not None,
        "sdxl_i2i_ready": I2I_PIPE is not None,
        "device": DEVICE
    }