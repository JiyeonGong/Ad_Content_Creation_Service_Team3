# C:\Users\devuser\Codeit\Ad_Content_Creation_Service_Team3\src\healthcare\backend.py

# ========================================
# í”„ë¡ íŠ¸ì—”ë“œ/ë²¡ì—”ë“œ ë¶„ë¦¬ ë²„ì „
# ========================================

import os
import re
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from openai import OpenAI
from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
import torch
from io import BytesIO
from PIL import Image

# ===============================
# ğŸŒ í™˜ê²½ ë³€ìˆ˜ ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# ===============================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL_GPT_MINI = "gpt-5-mini"
openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# ===============================
# FastAPI ì•± & CORS
# ===============================
app = FastAPI(title="Healthcare AI Content API")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ ë°°í¬ ì‹œ ë„ë©”ì¸ ì œí•œ ê°€ëŠ¥
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===============================
# GPT-5 Mini ë¬¸êµ¬ ìƒì„±
# ===============================
def parse_output(output):
    captions, hashtags = [], ""
    try:
        m = re.search(r"ë¬¸êµ¬:(.*?)í•´ì‹œíƒœê·¸:(.*)", output, re.S)
        if m:
            caption_text = m.group(1).strip()
            hashtags = m.group(2).strip()
            captions = [line.split(".",1)[1].strip() if "." in line else line.strip()
                        for line in caption_text.split("\n") if line.strip()]
        else:
            captions = [output]
    except Exception:
        captions = [output]
    return captions, hashtags

@app.post("/generate_captions")
def generate_captions(
    service_name: str = Form(...),
    features: str = Form(...),
    tone: str = Form("ì¹œê·¼í•˜ê³  ë™ê¸°ë¶€ì—¬")
):
    if not openai_client:
        return {"error": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    prompt = f"""
ë‹¹ì‹ ì€ í—¬ìŠ¤ì¼€ì–´ ì†Œìƒê³µì¸ì„ ìœ„í•œ ì „ë¬¸ ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ì— ìµœì í™”ëœ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

ìš”ì²­:
1. ì¸ìŠ¤íƒ€ê·¸ë¨ í™ë³´ ë¬¸êµ¬ 3ê°œ ì‘ì„±
    - ê° ë¬¸êµ¬: í›„í‚¹ â†’ í•µì‹¬ ë©”ì‹œì§€ â†’ CTA
    - ì´ëª¨í‹°ì½˜ ì‚¬ìš©
    - ë¬¸ì²´ ìŠ¤íƒ€ì¼: {tone}

[ì •ë³´]
ì„œë¹„ìŠ¤ ì¢…ë¥˜: í—¬ìŠ¤/í”¼íŠ¸ë‹ˆìŠ¤
ì„œë¹„ìŠ¤ëª…: {service_name}
í•µì‹¬ íŠ¹ì§•: {features}
ì§€ì—­: ì „êµ­/ì˜¨ë¼ì¸
ì´ë²¤íŠ¸: ì—†ìŒ

ì¶œë ¥ í˜•ì‹:
ë¬¸êµ¬:
1. [ë¬¸êµ¬1]
2. [ë¬¸êµ¬2]
3. [ë¬¸êµ¬3]

í•´ì‹œíƒœê·¸:
#[íƒœê·¸1] #[íƒœê·¸2] ... #[íƒœê·¸N]
"""
    response = openai_client.responses.create(
        model=MODEL_GPT_MINI,
        input=prompt,
        reasoning={"effort":"minimal"},
        max_output_tokens=512
    )
    captions, hashtags = parse_output(response.output_text.strip())
    return {"captions": captions, "hashtags": hashtags}

# ===============================
# SDXL T2I
# ===============================
pipe_t2i = None
def init_sdxl_t2i():
    global pipe_t2i
    if pipe_t2i is None:
        pipe_t2i = StableDiffusionXLPipeline.from_pretrained(
            "stabilityai/stable-diffusion-xl-base-1.0",
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
        ).to("cuda" if torch.cuda.is_available() else "cpu")
    return pipe_t2i

@app.post("/generate_image")
def generate_image(prompt: str = Form(...), width: int = Form(1024), height: int = Form(1024), steps: int = Form(30)):
    pipe = init_sdxl_t2i()
    negative_prompt = "low quality, blurry, text, watermark, distorted"
    result = pipe(prompt=prompt, negative_prompt=negative_prompt, width=width, height=height, num_inference_steps=steps)
    buf = BytesIO()
    result.images[0].save(buf, format="PNG")
    buf.seek(0)
    return {"image_bytes": buf.getvalue()}

# ===============================
# SDXL I2I
# ===============================
pipe_i2i = None
def init_sdxl_i2i():
    global pipe_i2i
    if pipe_i2i is None:
        pipe_i2i = StableDiffusionXLImg2ImgPipeline.from_pretrained(
            "stabilityai/stable-diffusion-xl-base-1.0",
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
        ).to("cuda" if torch.cuda.is_available() else "cpu")
    return pipe_i2i

@app.post("/edit_image")
def edit_image(
    image: UploadFile = File(...),
    prompt: str = Form(...),
    strength: float = Form(0.75),
    width: int = Form(1024),
    height: int = Form(1024),
    steps: int = Form(30)
):
    pipe = init_sdxl_i2i()
    input_image = Image.open(BytesIO(image.file.read())).convert("RGB").resize((width, height))
    negative_prompt = "low quality, blurry, text, watermark, distorted"
    
    result = pipe(prompt=prompt, image=input_image, strength=strength, negative_prompt=negative_prompt, num_inference_steps=steps)
    buf = BytesIO()
    result.images[0].save(buf, format="PNG")
    buf.seek(0)
    return {"image_bytes": buf.getvalue()}