# # C:\Users\devuser\Codeit\Ad_Content_Creation_Service_Team3\src\healthcare\backend.py
# #========================================
# # í”„ë¡ íŠ¸ì—”ë“œ/ë²¡ì—”ë“œ ë¶„ë¦¬ + ìºì‹œ ê²½ë¡œ ì§€ì • ë²„ì „
# #========================================

# import os
# import re
# from fastapi import FastAPI, UploadFile, File, Form
# from fastapi.middleware.cors import CORSMiddleware
# from openai import OpenAI
# from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
# import torch
# from io import BytesIO
# from PIL import Image

# # ===============================
# # ğŸŒ í™˜ê²½ ë³€ìˆ˜ ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# # ===============================
# OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# MODEL_GPT_MINI = "gpt-5-mini"
# openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# # ===============================
# # ğŸ’¾ ìºì‹œ ê²½ë¡œ ì„¤ì • (í”„ë¡œì íŠ¸ êµ¬ì¡° ê¸°ì¤€)
# # ===============================
# project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
# cache_root = os.path.join(project_root, "cache")
# os.makedirs(cache_root, exist_ok=True)

# hf_cache_dir = os.path.join(cache_root, "hf_models")
# os.makedirs(hf_cache_dir, exist_ok=True)

# print(f"[INFO] Hugging Face ëª¨ë¸ ìºì‹œ ê²½ë¡œ: {hf_cache_dir}")

# # ===============================
# # FastAPI ì•± & CORS
# # ===============================
# app = FastAPI(title="Healthcare AI Content API")
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],  # ì‹¤ì œ ë°°í¬ ì‹œ ë„ë©”ì¸ ì œí•œ ê°€ëŠ¥
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

# # ===============================
# # GPT-5 Mini ë¬¸êµ¬ ìƒì„±
# # ===============================
# def parse_output(output):
#     captions, hashtags = [], ""
#     try:
#         m = re.search(r"ë¬¸êµ¬:(.*?)í•´ì‹œíƒœê·¸:(.*)", output, re.S)
#         if m:
#             caption_text = m.group(1).strip()
#             hashtags = m.group(2).strip()
#             captions = [line.split(".", 1)[1].strip() if "." in line else line.strip()
#                         for line in caption_text.split("\n") if line.strip()]
#         else:
#             captions = [output]
#     except Exception:
#         captions = [output]
#     return captions, hashtags

# @app.post("/generate_captions")
# def generate_captions(
#     service_name: str = Form(...),
#     features: str = Form(...),
#     tone: str = Form("ì¹œê·¼í•˜ê³  ë™ê¸°ë¶€ì—¬")
# ):
#     if not openai_client:
#         return {"error": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

#     prompt = f"""
# ë‹¹ì‹ ì€ í—¬ìŠ¤ì¼€ì–´ ì†Œìƒê³µì¸ì„ ìœ„í•œ ì „ë¬¸ ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°ì…ë‹ˆë‹¤.
# ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ì— ìµœì í™”ëœ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

# ìš”ì²­:
# 1. ì¸ìŠ¤íƒ€ê·¸ë¨ í™ë³´ ë¬¸êµ¬ 3ê°œ ì‘ì„±
#     - ê° ë¬¸êµ¬: í›„í‚¹ â†’ í•µì‹¬ ë©”ì‹œì§€ â†’ CTA
#     - ì´ëª¨í‹°ì½˜ ì‚¬ìš©
#     - ë¬¸ì²´ ìŠ¤íƒ€ì¼: {tone}

# [ì •ë³´]
# ì„œë¹„ìŠ¤ ì¢…ë¥˜: í—¬ìŠ¤/í”¼íŠ¸ë‹ˆìŠ¤
# ì„œë¹„ìŠ¤ëª…: {service_name}
# í•µì‹¬ íŠ¹ì§•: {features}
# ì§€ì—­: ì „êµ­/ì˜¨ë¼ì¸
# ì´ë²¤íŠ¸: ì—†ìŒ

# ì¶œë ¥ í˜•ì‹:
# ë¬¸êµ¬:
# 1. [ë¬¸êµ¬1]
# 2. [ë¬¸êµ¬2]
# 3. [ë¬¸êµ¬3]

# í•´ì‹œíƒœê·¸:
# #[íƒœê·¸1] #[íƒœê·¸2] ... #[íƒœê·¸N]
# """
#     response = openai_client.responses.create(
#         model=MODEL_GPT_MINI,
#         input=prompt,
#         reasoning={"effort": "minimal"},
#         max_output_tokens=512
#     )
#     captions, hashtags = parse_output(response.output_text.strip())
#     return {"captions": captions, "hashtags": hashtags}

# # ===============================
# # SDXL T2I
# # ===============================
# pipe_t2i = None
# def init_sdxl_t2i():
#     global pipe_t2i
#     if pipe_t2i is None:
#         pipe_t2i = StableDiffusionXLPipeline.from_pretrained(
#             "stabilityai/stable-diffusion-xl-base-1.0",
#             cache_dir=hf_cache_dir,  # âœ… HF ëª¨ë¸ ìºì‹œ ê²½ë¡œ ì§€ì •
#             torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
#         ).to("cuda" if torch.cuda.is_available() else "cpu")
#     return pipe_t2i

# @app.post("/generate_image")
# def generate_image(
#     prompt: str = Form(...),
#     width: int = Form(1024),
#     height: int = Form(1024),
#     steps: int = Form(30)
# ):
#     pipe = init_sdxl_t2i()
#     negative_prompt = "low quality, blurry, text, watermark, distorted"
#     result = pipe(
#         prompt=prompt,
#         negative_prompt=negative_prompt,
#         width=width,
#         height=height,
#         num_inference_steps=steps
#     )
#     buf = BytesIO()
#     result.images[0].save(buf, format="PNG")
#     buf.seek(0)
#     return {"image_bytes": buf.getvalue()}

# # ===============================
# # SDXL I2I
# # ===============================
# pipe_i2i = None
# def init_sdxl_i2i():
#     global pipe_i2i
#     if pipe_i2i is None:
#         pipe_i2i = StableDiffusionXLImg2ImgPipeline.from_pretrained(
#             "stabilityai/stable-diffusion-xl-base-1.0",
#             cache_dir=hf_cache_dir,  # âœ… HF ëª¨ë¸ ìºì‹œ ê²½ë¡œ ì§€ì •
#             torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
#         ).to("cuda" if torch.cuda.is_available() else "cpu")
#     return pipe_i2i

# @app.post("/edit_image")
# def edit_image(
#     image: UploadFile = File(...),
#     prompt: str = Form(...),
#     strength: float = Form(0.75),
#     width: int = Form(1024),
#     height: int = Form(1024),
#     steps: int = Form(30)
# ):
#     pipe = init_sdxl_i2i()
#     input_image = Image.open(BytesIO(image.file.read())).convert("RGB").resize((width, height))
#     negative_prompt = "low quality, blurry, text, watermark, distorted"

#     result = pipe(
#         prompt=prompt,
#         image=input_image,
#         strength=strength,
#         negative_prompt=negative_prompt,
#         num_inference_steps=steps
#     )
#     buf = BytesIO()
#     result.images[0].save(buf, format="PNG")
#     buf.seek(0)
#     return {"image_bytes": buf.getvalue()}







# C:\Users\devuser\Codeit\Ad_Content_Creation_Service_Team3\src\healthcare\backend.py
#========================================
# í”„ë¡ íŠ¸ì—”ë“œ/ë²¡ì—”ë“œ ë¶„ë¦¬ + ìºì‹œ ê²½ë¡œ ì§€ì • ë²„ì „ + streamlit.py ê°œì„  ì‚¬í•­ ë°˜ì˜
#========================================

import os
from openai import OpenAI
from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
import torch
from io import BytesIO
from PIL import Image

# ====================================================
# ğŸŒ± í™˜ê²½ ë³€ìˆ˜
# ====================================================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL_GPT_MINI = "gpt-5-mini"

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = None
if OPENAI_API_KEY:
    try:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
    except Exception as e:
        print(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

# ====================================================
# ğŸ—„ ìºì‹œ ê²½ë¡œ
# ====================================================
cache_root = os.path.join(os.path.abspath(os.path.dirname(__file__)), "cache")
hf_cache_dir = os.path.join(cache_root, "hf_models")
os.makedirs(hf_cache_dir, exist_ok=True)

# ====================================================
# ğŸ“ GPT-5 Mini í™ë³´ ë¬¸êµ¬ + í•´ì‹œíƒœê·¸ ìƒì„±
# ====================================================
def generate_caption_and_hashtags(client, model, tone, info, hashtag_count=15):
    prompt = f"""
ë‹¹ì‹ ì€ í—¬ìŠ¤ì¼€ì–´ ì†Œìƒê³µì¸ì„ ìœ„í•œ ì „ë¬¸ ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ì— ìµœì í™”ëœ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

ìš”ì²­:
1. ì¸ìŠ¤íƒ€ê·¸ë¨ í™ë³´ ë¬¸êµ¬ 3ê°œ ì‘ì„±
    - ê° ë¬¸êµ¬: í›„í‚¹ â†’ í•µì‹¬ ë©”ì‹œì§€ â†’ CTA
    - ì´ëª¨í‹°ì½˜ ì‚¬ìš©
    - ë¬¸ì²´ ìŠ¤íƒ€ì¼: {tone}
2. í•´ì‹œíƒœê·¸ {hashtag_count}ê°œ ì¶”ì²œ (ì¤‘ë³µ ì œê±°)

[ì •ë³´]
ì„œë¹„ìŠ¤ ì¢…ë¥˜: {info['service_type']}
ì„œë¹„ìŠ¤ëª…: {info['service_name']}
í•µì‹¬ íŠ¹ì§•: {info['features']}
ì§€ì—­: {info['location']}
ì´ë²¤íŠ¸: {info['event_info']}

ì¶œë ¥ í˜•ì‹:
ë¬¸êµ¬:
1. [ë¬¸êµ¬1]
2. [ë¬¸êµ¬2]
3. [ë¬¸êµ¬3]

í•´ì‹œíƒœê·¸:
#[íƒœê·¸1] #[íƒœê·¸2] ... #[íƒœê·¸N]
"""
    try:
        response = client.responses.create(
            model=model,
            input=prompt,
            reasoning={"effort":"minimal"},
            max_output_tokens=512
        )
        return response.output_text.strip()
    except Exception as e:
        return f"ë¬¸êµ¬:\n1. [API ì˜¤ë¥˜]\ní•´ì‹œíƒœê·¸:\n#[APIì˜¤ë¥˜]"

# ====================================================
# ğŸ–¼ SDXL ì´ë¯¸ì§€ ìƒì„±
# ====================================================
def init_local_sdxl_t2i(model_id="stabilityai/stable-diffusion-xl-base-1.0"):
    pipe = StableDiffusionXLPipeline.from_pretrained(
        model_id,
        cache_dir=hf_cache_dir,
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
    )
    return pipe.to("cuda" if torch.cuda.is_available() else "cpu")

def init_local_sdxl_i2i(model_id="stabilityai/stable-diffusion-xl-base-1.0"):
    pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(
        model_id,
        cache_dir=hf_cache_dir,
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
    )
    return pipe.to("cuda" if torch.cuda.is_available() else "cpu")

def generate_image_local(pipe, prompt, width=1024, height=1024, steps=30):
    negative_prompt = "low quality, blurry, text, watermark, distorted"
    result = pipe(prompt=prompt, negative_prompt=negative_prompt, width=width, height=height, num_inference_steps=steps)
    image = result.images[0]
    buf = BytesIO()
    image.save(buf, format="PNG")
    buf.seek(0)
    return buf

def generate_image_i2i_local(pipe, input_image_bytes, prompt, strength=0.75, width=1024, height=1024, steps=30):
    negative_prompt = "low quality, blurry, text, watermark, distorted"
    input_image = Image.open(BytesIO(input_image_bytes)).convert("RGB").resize((width, height))
    result = pipe(prompt=prompt, image=input_image, strength=strength, negative_prompt=negative_prompt, num_inference_steps=steps)
    image = result.images[0]
    buf = BytesIO()
    image.save(buf, format="PNG")
    buf.seek(0)
    return buf

def caption_to_image_prompt(caption, style="Instagram banner"):
    return f"{caption}, {style}, vibrant, professional, motivational"