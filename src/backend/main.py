# main.py (ê°œì„ )
import base64
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import asyncio

from . import services

app = FastAPI(title="í—¬ìŠ¤ì¼€ì–´ AI ì½˜í…ì¸  API (ê°œì„ )")

# Pydantic schemas
class CaptionRequest(BaseModel):
    service_type: str
    service_name: str
    features: str
    location: str
    tone: str

class CaptionResponse(BaseModel):
    output_text: str

class T2IRequest(BaseModel):
    prompt: str
    width: int = 1024
    height: int = 1024
    steps: int = 4  # ğŸ†• FLUX-schnellì€ 4 steps ê¶Œì¥

class T2IResponse(BaseModel):
    image_base64: str

class I2IRequest(BaseModel):
    input_image_base64: str
    prompt: str
    strength: float = 0.75
    width: int = 1024
    height: int = 1024
    steps: int = 4  # ğŸ†• FLUX-schnellì€ 4 steps ê¶Œì¥

# ğŸ†• ê°œì„ : startupì—ì„œ ëª¨ë¸ ë¡œë“œ (1íšŒë§Œ)
@app.on_event("startup")
async def startup_event():
    """ì•± ì‹œì‘ ì‹œ ëª¨ë¸ì„ 1íšŒë§Œ ë¡œë“œ"""
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(None, services.init_image_pipelines)
    print("âœ… FastAPI ì‹œì‘ ì™„ë£Œ - ëª¨ë¸ ë¡œë“œë¨")

# ğŸ†• ê°œì„ : reload ì‹œ ëª¨ë¸ ì¬ë¡œë”© ë°©ì§€ë¥¼ ìœ„í•œ shutdown í•¸ë“¤ëŸ¬ ì œê±°
# (ê¸°ì¡´ì— ìˆì—ˆë‹¤ë©´) - uvicorn reload ì‹œ ë©”ëª¨ë¦¬ì— ëª¨ë¸ ìœ ì§€

# Endpoints
@app.post("/api/caption", response_model=CaptionResponse)
def create_caption(req: CaptionRequest):
    try:
        info = {
            "service_type": req.service_type,
            "service_name": req.service_name,
            "features": req.features,
            "location": req.location,
        }
        output_text = services.generate_caption_core(info, req.tone)
        return CaptionResponse(output_text=output_text)
    except RuntimeError as re_err:
        raise HTTPException(status_code=503, detail=str(re_err))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¬¸êµ¬ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

@app.post("/api/generate_t2i", response_model=T2IResponse)
async def generate_t2i_image(req: T2IRequest):
    steps = services.ensure_steps(req.steps)
    width = services.align_to_64(req.width)
    height = services.align_to_64(req.height)

    if width > 2048 or height > 2048:
        raise HTTPException(status_code=400, detail="width/height ê°’ì´ ë„ˆë¬´ í½ë‹ˆë‹¤.")

    try:
        loop = asyncio.get_event_loop()
        image_bytes = await loop.run_in_executor(
            None,
            services.generate_t2i_core,
            req.prompt,
            width,
            height,
            steps
        )
        b64 = base64.b64encode(image_bytes).decode("utf-8")
        return T2IResponse(image_base64=b64)
    except RuntimeError as re_err:
        raise HTTPException(status_code=503, detail=str(re_err))
    except Exception as e:
        err = str(e).lower()
        if "out of memory" in err or "cuda" in err:
            raise HTTPException(status_code=503, detail="GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
        raise HTTPException(status_code=500, detail=f"T2I ìƒì„± ì‹¤íŒ¨: {e}")

@app.post("/api/generate_i2i", response_model=T2IResponse)
async def generate_i2i_image(req: I2IRequest):
    steps = services.ensure_steps(req.steps)
    width = services.align_to_64(req.width)
    height = services.align_to_64(req.height)
    strength = float(req.strength)

    try:
        try:
            input_bytes = base64.b64decode(req.input_image_base64)
        except Exception:
            raise HTTPException(status_code=400, detail="ì…ë ¥ ì´ë¯¸ì§€ Base64 ë””ì½”ë”© ì‹¤íŒ¨")

        loop = asyncio.get_event_loop()
        image_bytes = await loop.run_in_executor(
            None,
            services.generate_i2i_core,
            input_bytes,
            req.prompt,
            strength,
            width,
            height,
            steps
        )
        b64 = base64.b64encode(image_bytes).decode("utf-8")
        return T2IResponse(image_base64=b64)
    except RuntimeError as re_err:
        raise HTTPException(status_code=503, detail=str(re_err))
    except Exception as e:
        err = str(e).lower()
        if "out of memory" in err or "cuda" in err:
            raise HTTPException(status_code=503, detail="GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
        raise HTTPException(status_code=500, detail=f"I2I ìƒì„± ì‹¤íŒ¨: {e}")

@app.get("/status")
def status():
    """ì„œë¹„ìŠ¤ ìƒíƒœ ë° ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    return services.get_service_status()

@app.get("/models")
def list_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    registry = services.registry
    models = {}
    
    for name in registry.list_models():
        models[name] = registry.get_model_info(name)
    
    return {
        "models": models,
        "current": services.model_loader.current_model_name if services.model_loader else None,
        "primary": registry.get_primary_model(),
        "fallback_chain": registry.get_fallback_models()
    }