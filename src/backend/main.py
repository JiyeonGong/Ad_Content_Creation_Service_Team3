# # C:\Users\devuser\Codeit\Ad_Content_Creation_Service_Team3\src\backend\main.py (ê°œì„ )
# import base64
# from fastapi import FastAPI, HTTPException
# from pydantic import BaseModel
# import asyncio

# from . import services

# app = FastAPI(title="í—¬ìŠ¤ì¼€ì–´ AI ì½˜í…ì¸  API (ê°œì„ )")

# # Pydantic schemas
# class CaptionRequest(BaseModel):
#     service_type: str
#     service_name: str
#     features: str
#     location: str
#     tone: str

# class CaptionResponse(BaseModel):
#     output_text: str

# class T2IRequest(BaseModel):
#     prompt: str
#     width: int = 1024
#     height: int = 1024
#     steps: int = 4  # ğŸ†• FLUX-schnellì€ 4 steps ê¶Œì¥

# class T2IResponse(BaseModel):
#     image_base64: str

# class I2IRequest(BaseModel):
#     input_image_base64: str
#     prompt: str
#     strength: float = 0.75
#     width: int = 1024
#     height: int = 1024
#     steps: int = 4  # ğŸ†• FLUX-schnellì€ 4 steps ê¶Œì¥

# # ğŸ†• ê°œì„ : startupì—ì„œ ëª¨ë¸ ë¡œë“œ (1íšŒë§Œ)
# @app.on_event("startup")
# async def startup_event():
#     """ì•± ì‹œì‘ ì‹œ ëª¨ë¸ì„ 1íšŒë§Œ ë¡œë“œ"""
#     loop = asyncio.get_event_loop()
#     await loop.run_in_executor(None, services.init_image_pipelines)
#     print("âœ… FastAPI ì‹œì‘ ì™„ë£Œ - ëª¨ë¸ ë¡œë“œë¨")

# # ğŸ†• ê°œì„ : reload ì‹œ ëª¨ë¸ ì¬ë¡œë”© ë°©ì§€ë¥¼ ìœ„í•œ shutdown í•¸ë“¤ëŸ¬ ì œê±°
# # (ê¸°ì¡´ì— ìˆì—ˆë‹¤ë©´) - uvicorn reload ì‹œ ë©”ëª¨ë¦¬ì— ëª¨ë¸ ìœ ì§€

# # Endpoints
# @app.post("/api/caption", response_model=CaptionResponse)
# def create_caption(req: CaptionRequest):
#     try:
#         info = {
#             "service_type": req.service_type,
#             "service_name": req.service_name,
#             "features": req.features,
#             "location": req.location,
#         }
#         output_text = services.generate_caption_core(info, req.tone)
#         return CaptionResponse(output_text=output_text)
#     except RuntimeError as re_err:
#         raise HTTPException(status_code=503, detail=str(re_err))
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=f"ë¬¸êµ¬ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

# @app.post("/api/generate_t2i", response_model=T2IResponse)
# async def generate_t2i_image(req: T2IRequest):
#     steps = services.ensure_steps(req.steps)
#     width = services.align_to_64(req.width)
#     height = services.align_to_64(req.height)

#     if width > 2048 or height > 2048:
#         raise HTTPException(status_code=400, detail="width/height ê°’ì´ ë„ˆë¬´ í½ë‹ˆë‹¤.")

#     try:
#         loop = asyncio.get_event_loop()
#         image_bytes = await loop.run_in_executor(
#             None,
#             services.generate_t2i_core,
#             req.prompt,
#             width,
#             height,
#             steps
#         )
#         b64 = base64.b64encode(image_bytes).decode("utf-8")
#         return T2IResponse(image_base64=b64)
#     except RuntimeError as re_err:
#         raise HTTPException(status_code=503, detail=str(re_err))
#     except Exception as e:
#         err = str(e).lower()
#         if "out of memory" in err or "cuda" in err:
#             raise HTTPException(status_code=503, detail="GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
#         raise HTTPException(status_code=500, detail=f"T2I ìƒì„± ì‹¤íŒ¨: {e}")

# @app.post("/api/generate_i2i", response_model=T2IResponse)
# async def generate_i2i_image(req: I2IRequest):
#     steps = services.ensure_steps(req.steps)
#     width = services.align_to_64(req.width)
#     height = services.align_to_64(req.height)
#     strength = float(req.strength)

#     try:
#         try:
#             input_bytes = base64.b64decode(req.input_image_base64)
#         except Exception:
#             raise HTTPException(status_code=400, detail="ì…ë ¥ ì´ë¯¸ì§€ Base64 ë””ì½”ë”© ì‹¤íŒ¨")

#         loop = asyncio.get_event_loop()
#         image_bytes = await loop.run_in_executor(
#             None,
#             services.generate_i2i_core,
#             input_bytes,
#             req.prompt,
#             strength,
#             width,
#             height,
#             steps
#         )
#         b64 = base64.b64encode(image_bytes).decode("utf-8")
#         return T2IResponse(image_base64=b64)
#     except RuntimeError as re_err:
#         raise HTTPException(status_code=503, detail=str(re_err))
#     except Exception as e:
#         err = str(e).lower()
#         if "out of memory" in err or "cuda" in err:
#             raise HTTPException(status_code=503, detail="GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
#         raise HTTPException(status_code=500, detail=f"I2I ìƒì„± ì‹¤íŒ¨: {e}")

# @app.get("/status")
# def status():
#     return {
#         "gpt_ready": services.openai_client is not None,
#         "image_pipeline_ready": services.T2I_PIPE is not None,
#         "device": services.DEVICE,
#         "model": services.MODEL_ID
#     }















# from fastapi import FastAPI, HTTPException
# import asyncio, base64

# from services import pipeline_loader, image_service, openai_service
# from models.schemas import CaptionRequest, CaptionResponse, T2IRequest, T2IResponse, I2IRequest

# app = FastAPI(title="í—¬ìŠ¤ì¼€ì–´ AI ì½˜í…ì¸  API (ëª¨ë¸ êµì²´ ê°€ëŠ¥)")

# @app.on_event("startup")
# async def startup_event():
#     loop = asyncio.get_event_loop()
#     await loop.run_in_executor(None, pipeline_loader.init_image_pipelines)
#     print("âœ… FastAPI ì‹œì‘ ì™„ë£Œ - ëª¨ë¸ ë¡œë“œë¨")

# @app.post("/api/caption", response_model=CaptionResponse)
# def create_caption(req: CaptionRequest):
#     try:
#         info = {
#             "service_type": req.service_type,
#             "service_name": req.service_name,
#             "features": req.features,
#             "location": req.location,
#         }
#         text = openai_service.generate_caption_core(info, req.tone)
#         return CaptionResponse(output_text=text)
#     except RuntimeError as e:
#         raise HTTPException(status_code=503, detail=str(e))
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=str(e))

# @app.post("/api/generate_t2i", response_model=T2IResponse)
# async def generate_t2i(req: T2IRequest):
#     try:
#         loop = asyncio.get_event_loop()
#         image_bytes = await loop.run_in_executor(None, image_service.generate_t2i_core, req.prompt, req.width, req.height, req.steps)
#         return T2IResponse(image_base64=base64.b64encode(image_bytes).decode("utf-8"))
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=str(e))

# @app.post("/api/generate_i2i", response_model=T2IResponse)
# async def generate_i2i(req: I2IRequest):
#     try:
#         input_bytes = base64.b64decode(req.input_image_base64)
#         loop = asyncio.get_event_loop()
#         image_bytes = await loop.run_in_executor(None, image_service.generate_i2i_core, input_bytes, req.prompt, req.strength, req.width, req.height, req.steps)
#         return T2IResponse(image_base64=base64.b64encode(image_bytes).decode("utf-8"))
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=str(e))

# @app.get("/status")
# def status():
#     return {
#         "model": pipeline_loader.CURRENT_MODEL,
#         "device": pipeline_loader.DEVICE,
#         "gpt_ready": openai_service.openai_client is not None,
#         "image_pipeline_ready": pipeline_loader.T2I_PIPE is not None
#     }






















from fastapi import FastAPI, HTTPException
import asyncio, base64

from services import pipeline_loader, image_service, openai_service
from models.schemas import CaptionRequest, CaptionResponse, T2IRequest, T2IResponse, I2IRequest


from fastapi import Request
from fastapi.responses import JSONResponse
import traceback



app = FastAPI(title="í—¬ìŠ¤ì¼€ì–´ AI ì½˜í…ì¸  API (ëª¨ë¸ êµì²´ ê°€ëŠ¥)")








@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    print("ğŸ”¥ğŸ”¥ğŸ”¥ ì„œë²„ ì—ëŸ¬ ë°œìƒ! ì „ì²´ Traceback ì¶œë ¥:")
    traceback.print_exc()   # <-- ì½˜ì†”ì— ì „ì²´ ì—ëŸ¬ ì¶œë ¥
    return JSONResponse(
        status_code=500,
        content={"detail": str(exc)},
    )



@app.on_event("startup")
async def startup_event():
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(None, pipeline_loader.init_image_pipelines)
    print("âœ… FastAPI ì‹œì‘ ì™„ë£Œ - ëª¨ë¸ ë¡œë“œë¨")





@app.post("/api/caption", response_model=CaptionResponse)
def create_caption(req: CaptionRequest):
    try:
        info = {
            "service_type": req.service_type,
            "service_name": req.service_name,
            "features": req.features,
            "location": req.location,
        }
        text = openai_service.generate_caption_core(info, req.tone)
        return CaptionResponse(output_text=text)
    except RuntimeError as e:
        raise HTTPException(status_code=503, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/generate_t2i", response_model=T2IResponse)
async def generate_t2i(req: T2IRequest):
    try:
        loop = asyncio.get_event_loop()
        image_bytes = await loop.run_in_executor(
            None,
            image_service.generate_t2i_core,
            req.prompt,
            req.width,
            req.height,
            req.steps
        )

        if not image_bytes:
            raise RuntimeError("ì´ë¯¸ì§€ ë°”ì´íŠ¸ ìƒì„± ì‹¤íŒ¨ (None ë°˜í™˜ë¨)")

        return T2IResponse(
            image_base64=base64.b64encode(image_bytes).decode("utf-8")
        )

    except Exception as e:
        print("ğŸ”¥ generate_t2i API ë‚´ë¶€ ì—ëŸ¬:", e)
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/generate_i2i", response_model=T2IResponse)
async def generate_i2i(req: I2IRequest):
    try:
        input_bytes = base64.b64decode(req.input_image_base64)
        loop = asyncio.get_event_loop()
        image_bytes = await loop.run_in_executor(None, image_service.generate_i2i_core, input_bytes, req.prompt, req.strength, req.width, req.height, req.steps)
        return T2IResponse(image_base64=base64.b64encode(image_bytes).decode("utf-8"))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/status")
def status():
    return {
        "model": pipeline_loader.CURRENT_MODEL,
        "device": pipeline_loader.DEVICE,
        "gpt_ready": openai_service.openai_client is not None,
        "image_pipeline_ready": pipeline_loader.T2I_PIPE is not None
    }






