# main.py (ê°œì„ )
import base64
import time
from typing import Optional
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import asyncio

from . import services

app = FastAPI(title="í—¬ìŠ¤ì¼€ì–´ AI ì½˜í…ì¸  API (ê°œì„ )")

# ì„œë²„ ì‹œì‘ ì‹œê°„ (ì¬ì‹œì‘ ê°ì§€ìš©)
SERVER_START_TIME = time.time()

# Pydantic schemas
class CaptionRequest(BaseModel):
    service_type: str
    service_name: str
    features: str
    location: str
    tone: str

class CaptionResponse(BaseModel):
    output_text: str

class T2IRequest(BaseModel):
    prompt: str
    width: int = 1024
    height: int = 1024
    steps: int = 4  # ğŸ†• FLUX-schnellì€ 4 steps ê¶Œì¥
    guidance_scale: Optional[float] = None  # FLUX-devëŠ” 3.5 ê¶Œì¥, schnellì€ None

class T2IResponse(BaseModel):
    image_base64: str

class I2IRequest(BaseModel):
    input_image_base64: str
    prompt: str
    strength: float = 0.75
    width: int = 1024
    height: int = 1024
    steps: int = 4  # ğŸ†• FLUX-schnellì€ 4 steps ê¶Œì¥

# ğŸ†• ê°œì„ : startupì—ì„œ ëª¨ë¸ ë¡œë“œ (1íšŒë§Œ)
@app.on_event("startup")
async def startup_event():
    """ì•± ì‹œì‘ ì‹œ ì´ˆê¸°í™” (ëª¨ë¸ ìë™ ë¡œë”©ì€ í•˜ì§€ ì•ŠìŒ)"""
    # ë””í´íŠ¸ unload ìƒíƒœ ìœ ì§€ë¥¼ ìœ„í•´ ìë™ ë¡œë”© ì œê±°
    print("âœ… FastAPI ì‹œì‘ ì™„ë£Œ - ëª¨ë¸ì€ Unload ìƒíƒœì…ë‹ˆë‹¤.")

# ğŸ†• ê°œì„ : reload ì‹œ ëª¨ë¸ ì¬ë¡œë”© ë°©ì§€ë¥¼ ìœ„í•œ shutdown í•¸ë“¤ëŸ¬ ì œê±°
# (ê¸°ì¡´ì— ìˆì—ˆë‹¤ë©´) - uvicorn reload ì‹œ ë©”ëª¨ë¦¬ì— ëª¨ë¸ ìœ ì§€

# Endpoints
@app.post("/api/caption", response_model=CaptionResponse)
def create_caption(req: CaptionRequest):
    try:
        info = {
            "service_type": req.service_type,
            "service_name": req.service_name,
            "features": req.features,
            "location": req.location,
        }
        output_text = services.generate_caption_core(info, req.tone)
        return CaptionResponse(output_text=output_text)
    except RuntimeError as re_err:
        raise HTTPException(status_code=503, detail=str(re_err))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¬¸êµ¬ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

@app.post("/api/generate_t2i", response_model=T2IResponse)
async def generate_t2i_image(req: T2IRequest):
    steps = services.ensure_steps(req.steps)
    width = services.align_to_64(req.width)
    height = services.align_to_64(req.height)
    guidance_scale = req.guidance_scale

    if width > 2048 or height > 2048:
        raise HTTPException(status_code=400, detail="width/height ê°’ì´ ë„ˆë¬´ í½ë‹ˆë‹¤.")

    try:
        loop = asyncio.get_event_loop()
        image_bytes = await loop.run_in_executor(
            None,
            services.generate_t2i_core,
            req.prompt,
            width,
            height,
            steps,
            guidance_scale
        )
        b64 = base64.b64encode(image_bytes).decode("utf-8")
        return T2IResponse(image_base64=b64)
    except RuntimeError as re_err:
        raise HTTPException(status_code=503, detail=str(re_err))
    except Exception as e:
        err = str(e).lower()
        if "out of memory" in err or "cuda" in err:
            raise HTTPException(status_code=503, detail="GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
        raise HTTPException(status_code=500, detail=f"T2I ìƒì„± ì‹¤íŒ¨: {e}")

@app.post("/api/generate_i2i", response_model=T2IResponse)
async def generate_i2i_image(req: I2IRequest):
    steps = services.ensure_steps(req.steps)
    width = services.align_to_64(req.width)
    height = services.align_to_64(req.height)
    strength = float(req.strength)

    try:
        try:
            input_bytes = base64.b64decode(req.input_image_base64)
        except Exception:
            raise HTTPException(status_code=400, detail="ì…ë ¥ ì´ë¯¸ì§€ Base64 ë””ì½”ë”© ì‹¤íŒ¨")

        loop = asyncio.get_event_loop()
        image_bytes = await loop.run_in_executor(
            None,
            services.generate_i2i_core,
            input_bytes,
            req.prompt,
            strength,
            width,
            height,
            steps
        )
        b64 = base64.b64encode(image_bytes).decode("utf-8")
        return T2IResponse(image_base64=b64)
    except RuntimeError as re_err:
        raise HTTPException(status_code=503, detail=str(re_err))
    except Exception as e:
        err = str(e).lower()
        if "out of memory" in err or "cuda" in err:
            raise HTTPException(status_code=503, detail="GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
        raise HTTPException(status_code=500, detail=f"I2I ìƒì„± ì‹¤íŒ¨: {e}")

@app.get("/status")
def status():
    """ì„œë¹„ìŠ¤ ìƒíƒœ ë° ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    result = services.get_service_status()
    result["server_start_time"] = SERVER_START_TIME
    return result

@app.get("/models")
def list_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    registry = services.registry
    models = {}

    for name in registry.list_models():
        models[name] = registry.get_model_info(name)

    return {
        "models": models,
        "current": services.model_loader.current_model_name if services.model_loader else None,
        "primary": registry.get_primary_model(),
        "fallback_chain": registry.get_fallback_models()
    }

class SwitchModelRequest(BaseModel):
    model_name: str

# ëª¨ë¸ ì „í™˜ ìƒíƒœ ê´€ë¦¬
_model_switch_status = {
    "in_progress": False,
    "target_model": None,
    "success": None,
    "message": None,
    "error": None
}
_switch_task = None

@app.post("/api/switch_model")
def switch_model(req: SwitchModelRequest):
    """ëª¨ë¸ ì „í™˜ (ë™ê¸° - ê¸°ì¡´ í˜¸í™˜)"""
    result = services.switch_model(req.model_name)

    if not result["success"]:
        raise HTTPException(status_code=400, detail=result["message"])

    return result

@app.post("/api/switch_model_async")
async def switch_model_async(req: SwitchModelRequest):
    """ëª¨ë¸ ì „í™˜ (ë¹„ë™ê¸° - ì¦‰ì‹œ ì‘ë‹µ)"""
    global _model_switch_status, _switch_task

    # ì´ë¯¸ ì „í™˜ ì¤‘ì´ë©´ ê±°ë¶€
    if _model_switch_status["in_progress"]:
        raise HTTPException(
            status_code=409,
            detail=f"ëª¨ë¸ ì „í™˜ ì§„í–‰ ì¤‘: {_model_switch_status['target_model']}"
        )

    # ìƒíƒœ ì´ˆê¸°í™”
    _model_switch_status = {
        "in_progress": True,
        "target_model": req.model_name,
        "success": None,
        "message": "ëª¨ë¸ ì „í™˜ ì‹œì‘...",
        "error": None
    }

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëª¨ë¸ ì „í™˜ ì‹¤í–‰
    loop = asyncio.get_event_loop()
    _switch_task = loop.run_in_executor(None, _do_switch_model, req.model_name)

    return {
        "status": "started",
        "target_model": req.model_name,
        "message": "ëª¨ë¸ ì „í™˜ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. /api/switch_model_statusë¡œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”."
    }

def _do_switch_model(model_name: str):
    """ë°±ê·¸ë¼ìš´ë“œ ëª¨ë¸ ì „í™˜ ì‹¤í–‰"""
    global _model_switch_status
    try:
        result = services.switch_model(model_name)
        _model_switch_status["success"] = result["success"]
        _model_switch_status["message"] = result["message"]
        if not result["success"]:
            _model_switch_status["error"] = result["message"]
    except Exception as e:
        _model_switch_status["success"] = False
        _model_switch_status["message"] = f"ëª¨ë¸ ì „í™˜ ì‹¤íŒ¨: {e}"
        _model_switch_status["error"] = str(e)
    finally:
        _model_switch_status["in_progress"] = False

@app.get("/api/switch_model_status")
def get_switch_model_status():
    """ëª¨ë¸ ì „í™˜ ìƒíƒœ ì¡°íšŒ"""
    current_model = None
    if services.model_loader and services.model_loader.is_loaded():
        current_model = services.model_loader.current_model_name

    return {
        **_model_switch_status,
        "current_model": current_model
    }

@app.post("/api/load_model")
def load_model(req: SwitchModelRequest):
    """ëª¨ë¸ ë¡œë“œ (Switch Model ì¬ì‚¬ìš©)"""
    # ë¡œë“œë„ ê²°êµ­ switch_modelê³¼ ë™ì¼í•œ ë¡œì§
    result = services.switch_model(req.model_name)
    if not result["success"]:
        raise HTTPException(status_code=400, detail=result["message"])
    return result

@app.post("/api/unload_model")
def unload_model():
    """ëª¨ë¸ ì–¸ë¡œë“œ"""
    return services.unload_model_service()
