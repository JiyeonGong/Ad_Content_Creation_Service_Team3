# # src/backend/main.py
# # ============================================================
# # ğŸš€ FastAPI ë°±ì—”ë“œ API ì„œë²„ (ê²Œì´íŠ¸ì›¨ì´ ì—­í• )
# # - AI ì¶”ë¡  ë¡œì§ì€ 'services.py'ë¡œ ìœ„ì„
# # - Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜
# # ============================================================

# import base64
# from fastapi import FastAPI, HTTPException, Body
# from pydantic import BaseModel, Field

# # â­ï¸ 1. AI í•µì‹¬ ë¡œì§ì„ services ëª¨ë“ˆì—ì„œ import
# from . import services

# # ============================================================
# # ğŸ“œ Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜ (ë°ì´í„° êµ¬ì¡°)
# # (ì´ ë¶€ë¶„ì€ ë³€ê²½ ì—†ìŒ)
# # ============================================================

# class CaptionRequest(BaseModel):
#     service_type: str = Field(..., description="ì„œë¹„ìŠ¤ ì¢…ë¥˜ (ì˜ˆ: í—¬ìŠ¤ì¥)")
#     service_name: str = Field(..., description="ì œí’ˆ/í´ë˜ìŠ¤ ì´ë¦„")
#     features: str = Field(..., description="í•µì‹¬ íŠ¹ì§• ë° ì¥ì ")
#     location: str = Field(..., description="ì§€ì—­")
#     tone: str = Field(..., description="ë¬¸ì²´ ìŠ¤íƒ€ì¼")

# class CaptionResponse(BaseModel):
#     output_text: str = Field(..., description="GPT-5 Miniê°€ ìƒì„±í•œ ì›ë³¸ í…ìŠ¤íŠ¸")

# class T2IRequest(BaseModel):
#     prompt: str = Field(..., description="ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸")
#     width: int = 1024
#     height: int = 1024
#     steps: int = 30

# class T2IResponse(BaseModel):
#     image_base64: str = Field(..., description="ìƒì„±ëœ ì´ë¯¸ì§€ì˜ Base64 ì¸ì½”ë”© ë¬¸ìì—´ (PNG í˜•ì‹)")

# class I2IRequest(BaseModel):
#     input_image_base64: str = Field(..., description="ì›ë³¸ ì´ë¯¸ì§€ì˜ Base64 ì¸ì½”ë”© ë¬¸ìì—´ (PNG/JPG)")
#     prompt: str = Field(..., description="ì´ë¯¸ì§€ í¸ì§‘ í”„ë¡¬í”„íŠ¸")
#     strength: float = 0.75
#     width: int = 1024
#     height: int = 1024
#     steps: int = 30

# # ============================================================
# # ğŸš€ FastAPI ì•± ìƒì„± ë° ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
# # ============================================================

# app = FastAPI(title="í—¬ìŠ¤ì¼€ì–´ AI ì½˜í…ì¸  API")

# @app.on_event("startup")
# async def startup_event():
#     """ì„œë²„ ì‹œì‘ ì‹œ SDXL ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤. (services ëª¨ë“ˆì˜ í•¨ìˆ˜ í˜¸ì¶œ)"""
#     # â­ï¸ 2. servicesì˜ ì´ˆê¸°í™” í•¨ìˆ˜ í˜¸ì¶œ
#     services.init_sdxl_pipelines()

# # ============================================================
# # ğŸš€ API ì—”ë“œí¬ì¸íŠ¸ ì •ì˜ (í•µì‹¬ ë¡œì§ì€ 'services'ë¡œ ìœ„ì„)
# # ============================================================

# @app.post("/api/caption", response_model=CaptionResponse)
# async def create_caption(request: CaptionRequest):
#     """
#     GPT-5 Minië¥¼ ì‚¬ìš©í•˜ì—¬ í™ë³´ ë¬¸êµ¬ì™€ í•´ì‹œíƒœê·¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
#     """
#     if not services.openai_client:
#         raise HTTPException(status_code=503, detail="GPT-5 Mini ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
#     info = {
#         "service_type": request.service_type,
#         "service_name": request.service_name,
#         "features": request.features,
#         "location": request.location,
#     }

#     try:
#         # â­ï¸ 3. servicesì˜ í•µì‹¬ í•¨ìˆ˜ í˜¸ì¶œ
#         output_text = services.generate_caption_core(info, request.tone)
#         return CaptionResponse(output_text=output_text)
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=f"ë¬¸êµ¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# @app.post("/api/generate_t2i", response_model=T2IResponse)
# async def generate_t2i_image(request: T2IRequest):
#     """
#     SDXL T2Ië¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
#     """
#     if not services.T2I_PIPE:
#         raise HTTPException(status_code=503, detail="SDXL T2I ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

#     try:
#         # â­ï¸ 3. servicesì˜ í•µì‹¬ í•¨ìˆ˜ í˜¸ì¶œ
#         image_bytes = await app.loop.run_in_executor(
#             None, 
#             services.generate_t2i_core,
#             request.prompt,
#             request.width,
#             request.height,
#             request.steps
#         )
        
#         image_base64 = base64.b64encode(image_bytes).decode('utf-8')
#         return T2IResponse(image_base64=image_base64)
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=f"T2I ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# @app.post("/api/generate_i2i", response_model=T2IResponse) 
# async def generate_i2i_image(request: I2IRequest):
#     """
#     SDXL I2Ië¥¼ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í¸ì§‘/í•©ì„± ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
#     """
#     if not services.I2I_PIPE:
#         raise HTTPException(status_code=503, detail="SDXL I2I ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
#     try:
#         input_image_bytes = base64.b64decode(request.input_image_base64)
        
#         # â­ï¸ 3. servicesì˜ í•µì‹¬ í•¨ìˆ˜ í˜¸ì¶œ
#         image_bytes = await app.loop.run_in_executor(
#             None,
#             services.generate_i2i_core,
#             input_image_bytes,
#             request.prompt,
#             request.strength,
#             request.width,
#             request.height,
#             request.steps
#         )
        
#         image_base64 = base64.b64encode(image_bytes).decode('utf-8')
#         return T2IResponse(image_base64=image_base64)
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=f"I2I ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# # ìƒíƒœ í™•ì¸ìš© ì—”ë“œí¬ì¸íŠ¸ (servicesì˜ ë³€ìˆ˜ í™•ì¸)
# @app.get("/status")
# def get_status():
#     return {
#         "gpt_ready": services.openai_client is not None,
#         "sdxl_t2i_ready": services.T2I_PIPE is not None,
#         "sdxl_i2i_ready": services.I2I_PIPE is not None,
#         "device": services.DEVICE
#     }























# main.py (ê°œì„ )
import base64
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import asyncio

from . import services

app = FastAPI(title="í—¬ìŠ¤ì¼€ì–´ AI ì½˜í…ì¸  API (ê°œì„ )")

# Pydantic schemas
class CaptionRequest(BaseModel):
    service_type: str
    service_name: str
    features: str
    location: str
    tone: str

class CaptionResponse(BaseModel):
    output_text: str

class T2IRequest(BaseModel):
    prompt: str
    width: int = 1024
    height: int = 1024
    steps: int = 4  # ğŸ†• FLUX-schnellì€ 4 steps ê¶Œì¥

class T2IResponse(BaseModel):
    image_base64: str

class I2IRequest(BaseModel):
    input_image_base64: str
    prompt: str
    strength: float = 0.75
    width: int = 1024
    height: int = 1024
    steps: int = 4  # ğŸ†• FLUX-schnellì€ 4 steps ê¶Œì¥

# ğŸ†• ê°œì„ : startupì—ì„œ ëª¨ë¸ ë¡œë“œ (1íšŒë§Œ)
@app.on_event("startup")
async def startup_event():
    """ì•± ì‹œì‘ ì‹œ ëª¨ë¸ì„ 1íšŒë§Œ ë¡œë“œ"""
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(None, services.init_image_pipelines)
    print("âœ… FastAPI ì‹œì‘ ì™„ë£Œ - ëª¨ë¸ ë¡œë“œë¨")

# ğŸ†• ê°œì„ : reload ì‹œ ëª¨ë¸ ì¬ë¡œë”© ë°©ì§€ë¥¼ ìœ„í•œ shutdown í•¸ë“¤ëŸ¬ ì œê±°
# (ê¸°ì¡´ì— ìˆì—ˆë‹¤ë©´) - uvicorn reload ì‹œ ë©”ëª¨ë¦¬ì— ëª¨ë¸ ìœ ì§€

# Endpoints
@app.post("/api/caption", response_model=CaptionResponse)
def create_caption(req: CaptionRequest):
    try:
        info = {
            "service_type": req.service_type,
            "service_name": req.service_name,
            "features": req.features,
            "location": req.location,
        }
        output_text = services.generate_caption_core(info, req.tone)
        return CaptionResponse(output_text=output_text)
    except RuntimeError as re_err:
        raise HTTPException(status_code=503, detail=str(re_err))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¬¸êµ¬ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

@app.post("/api/generate_t2i", response_model=T2IResponse)
async def generate_t2i_image(req: T2IRequest):
    steps = services.ensure_steps(req.steps)
    width = services.align_to_64(req.width)
    height = services.align_to_64(req.height)

    if width > 2048 or height > 2048:
        raise HTTPException(status_code=400, detail="width/height ê°’ì´ ë„ˆë¬´ í½ë‹ˆë‹¤.")

    try:
        loop = asyncio.get_event_loop()
        image_bytes = await loop.run_in_executor(
            None,
            services.generate_t2i_core,
            req.prompt,
            width,
            height,
            steps
        )
        b64 = base64.b64encode(image_bytes).decode("utf-8")
        return T2IResponse(image_base64=b64)
    except RuntimeError as re_err:
        raise HTTPException(status_code=503, detail=str(re_err))
    except Exception as e:
        err = str(e).lower()
        if "out of memory" in err or "cuda" in err:
            raise HTTPException(status_code=503, detail="GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
        raise HTTPException(status_code=500, detail=f"T2I ìƒì„± ì‹¤íŒ¨: {e}")

@app.post("/api/generate_i2i", response_model=T2IResponse)
async def generate_i2i_image(req: I2IRequest):
    steps = services.ensure_steps(req.steps)
    width = services.align_to_64(req.width)
    height = services.align_to_64(req.height)
    strength = float(req.strength)

    try:
        try:
            input_bytes = base64.b64decode(req.input_image_base64)
        except Exception:
            raise HTTPException(status_code=400, detail="ì…ë ¥ ì´ë¯¸ì§€ Base64 ë””ì½”ë”© ì‹¤íŒ¨")

        loop = asyncio.get_event_loop()
        image_bytes = await loop.run_in_executor(
            None,
            services.generate_i2i_core,
            input_bytes,
            req.prompt,
            strength,
            width,
            height,
            steps
        )
        b64 = base64.b64encode(image_bytes).decode("utf-8")
        return T2IResponse(image_base64=b64)
    except RuntimeError as re_err:
        raise HTTPException(status_code=503, detail=str(re_err))
    except Exception as e:
        err = str(e).lower()
        if "out of memory" in err or "cuda" in err:
            raise HTTPException(status_code=503, detail="GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
        raise HTTPException(status_code=500, detail=f"I2I ìƒì„± ì‹¤íŒ¨: {e}")

@app.get("/status")
def status():
    return {
        "gpt_ready": services.openai_client is not None,
        "image_pipeline_ready": services.T2I_PIPE is not None,
        "device": services.DEVICE,
        "model": services.MODEL_ID
    }