# src/backend/text_overlay.py
"""
í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ê¸°ëŠ¥ - 3D ìº˜ë¦¬ê·¸ë¼í”¼ ìƒì„±
ControlNet Depth SDXLì„ í™œìš©í•œ 3D ë Œë”ë§ (íŒ€ì› ì½”ë“œ ê¸°ë°˜)
"""
import os
import cv2
import numpy as np
from PIL import Image, ImageFont, ImageDraw
from rembg import remove, new_session
import torch
from diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline

# ì„¸ì…˜ ë¡œë“œ
rembg_session = new_session("u2net")

# ControlNet ìº˜ë¦¬ê·¸ë¼í”¼ ì „ìš© íŒŒì´í”„ë¼ì¸ (lazy loading)
_calligraphy_pipeline = None 

def create_base_text_image(text: str, font_path: str, font_size: int = 600) -> Image.Image:
    """
    ê¸°ë³¸ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (íŒ€ì› ì½”ë“œ)
    """
    # ë””ë²„ê¹… ë¡œê·¸
    print(f"ğŸ” [ë””ë²„ê¹…] í°íŠ¸ ë¡œë”© ì‹œë„: '{font_path}'")
    if not os.path.exists(font_path):
        error_msg = f"âŒ í°íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤! ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {font_path}"
        print(error_msg)
        raise FileNotFoundError(error_msg)
    try:
        font = ImageFont.truetype(font_path, font_size)
    except Exception as e:
        print(f"âŒ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise e
    
    # í…ìŠ¤íŠ¸ ë§Œë“¤ê¸°
    dummy = ImageDraw.Draw(Image.new("RGB", (1, 1)))
    bbox = dummy.textbbox((0, 0), text, font=font)
    w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]
    padding = 200
    cw = ((w + padding) // 64 + 1) * 64
    ch = ((h + padding) // 64 + 1) * 64
    cw, ch = max(1024, cw), max(1024, ch)
    img = Image.new("RGB", (cw, ch), "black")
    draw = ImageDraw.Draw(img)
    tx = (cw - w) // 2 - bbox[0]
    ty = (ch - h) // 2 - bbox[1]
    draw.text((tx, ty), text, font=font, fill="white")
    return img

def get_calligraphy_pipeline():
    """
    ìº˜ë¦¬ê·¸ë¼í”¼ ì „ìš© ControlNet íŒŒì´í”„ë¼ì¸ ë¡œë“œ (lazy loading)
    
    Returns:
        StableDiffusionXLControlNetPipeline: ControlNet Depth SDXL íŒŒì´í”„ë¼ì¸
    """
    global _calligraphy_pipeline
    if _calligraphy_pipeline is None:
        print("ğŸ”§ ìº˜ë¦¬ê·¸ë¼í”¼ ì „ìš© ControlNet Depth SDXL íŒŒì´í”„ë¼ì¸ ë¡œë”© ì¤‘...")
        
        # ControlNet Depth ëª¨ë¸ ê²½ë¡œ (Hugging Face ìºì‹œ í˜•ì‹)
        controlnet_path = "diffusers/controlnet-depth-sdxl-1.0-small"
        controlnet_local = "/home/shared/models--diffusers--controlnet-depth-sdxl-1.0-small"
        
        # SDXL Base ëª¨ë¸ ê²½ë¡œ
        sdxl_base_path = "stabilityai/stable-diffusion-xl-base-1.0"
        sdxl_local = "/home/shared/models--stabilityai--stable-diffusion-xl-base-1.0"
        
        # SDXL VAE ê²½ë¡œ
        vae_path = "madebyollin/sdxl-vae-fp16-fix"
        vae_local = "/home/shared/models--madebyollin--sdxl-vae-fp16-fix"
        
        try:
            from diffusers import AutoencoderKL
            
            # VAE ë¡œë“œ (ë¡œì»¬ ìºì‹œ ìš°ì„ )
            vae = AutoencoderKL.from_pretrained(
                vae_path,
                cache_dir="/home/shared",
                local_files_only=True,
                torch_dtype=torch.float16
            )
            
            # ControlNet ë¡œë“œ (ë¡œì»¬ ìºì‹œ ìš°ì„ )
            controlnet = ControlNetModel.from_pretrained(
                controlnet_path,
                cache_dir="/home/shared",
                local_files_only=True,
                torch_dtype=torch.float16
            )
            
            # SDXL + ControlNet íŒŒì´í”„ë¼ì¸ ìƒì„± (ë¡œì»¬ ìºì‹œ ìš°ì„ )
            # meta í…ì„œ ë¬¸ì œ í•´ê²°: device_map="auto" ì‚¬ìš©
            _calligraphy_pipeline = StableDiffusionXLControlNetPipeline.from_pretrained(
                sdxl_base_path,
                controlnet=controlnet,
                vae=vae,
                cache_dir="/home/shared",
                local_files_only=True,
                torch_dtype=torch.float16,
                device_map="auto"  # meta í…ì„œ ìë™ ì²˜ë¦¬
            )
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            # enable_model_cpu_offload()ëŠ” device_map="auto"ì™€ í•¨ê»˜ ì‚¬ìš© ë¶ˆê°€
            # _calligraphy_pipeline.enable_model_cpu_offload()
            _calligraphy_pipeline.enable_vae_slicing()
            
            print("âœ… ìº˜ë¦¬ê·¸ë¼í”¼ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ìº˜ë¦¬ê·¸ë¼í”¼ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    return _calligraphy_pipeline

def apply_controlnet_3d_rendering(
    base_image: Image.Image,
    color_hex: str,
    style: str = "default"
) -> Image.Image:
    """
    ControlNet Depth SDXLì„ ì‚¬ìš©í•˜ì—¬ 3D ë Œë”ë§ ì ìš© (íŒ€ì› ì½”ë“œ)
    
    í‘ë°± í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ê¹Šì´ ë§µìœ¼ë¡œ ì‚¬ìš©í•˜ê³ ,
    ìƒ‰ìƒê³¼ ìŠ¤íƒ€ì¼ì€ í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•´ ControlNetì— ì „ë‹¬í•˜ì—¬
    ë‹¤ì±„ë¡œìš´ 3D ë Œë”ë§ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.
    
    Args:
        base_image: í‘ë°± í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ (í˜•íƒœ ì œì–´ìš©)
        color_hex: ì›í•˜ëŠ” ìƒ‰ìƒ HEX ì½”ë“œ
        style: ë Œë”ë§ ìŠ¤íƒ€ì¼
    
    Returns:
        PIL.Image: 3D ë Œë”ë§ì´ ì ìš©ëœ ì»¬ëŸ¬ ì´ë¯¸ì§€
    """
    try:
        print(f"ğŸ¨ ControlNet 3D ë Œë”ë§ ì‹œì‘ (ìƒ‰ìƒ: {color_hex}, ìŠ¤íƒ€ì¼: {style})")
        
        # ìƒ‰ìƒ ì´ë¦„ ë§¤í•‘ (HEX -> ì˜ì–´ ìƒ‰ìƒëª…)
        color_map = {
            "#FF0000": "red", "#FF5733": "orange red",
            "#FFA500": "orange", "#FFD700": "gold",
            "#FFFF00": "yellow", "#00FF00": "green",
            "#00FFFF": "cyan", "#0000FF": "blue",
            "#FF00FF": "magenta", "#800080": "purple",
            "#FFFFFF": "white", "#000000": "black",
            "#C0C0C0": "silver", "#FFE4E1": "rose"
        }
        
        color_name = color_map.get(color_hex.upper(), "vibrant colored")
        
        # ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        style_prompts = {
            "default": f"3D {color_name} calligraphy text, natural embossed letters, professional studio lighting, high quality, detailed texture, realistic depth",
            "emboss": f"3D {color_name} embossed calligraphy, raised metallic surface, dramatic shadows, reflective finish, photorealistic, strong depth effect",
            "carved": f"3D {color_name} carved calligraphy, engraved stone letters, chiseled effect, deep grooves, ancient style, strong relief",
            "floating": f"3D {color_name} floating calligraphy, levitating letters, depth of field, soft shadows, cinematic lighting, aerial perspective"
        }
        
        prompt = style_prompts.get(style, style_prompts["default"])
        negative_prompt = "flat, 2d, low quality, blurry, distorted, monochrome, grayscale"
        
        print(f"  í”„ë¡¬í”„íŠ¸: {prompt}")
        
        # ControlNet íŒŒì´í”„ë¼ì¸ ë¡œë“œ
        pipeline = get_calligraphy_pipeline()
        
        # 3D ë Œë”ë§ ìƒì„±
        result = pipeline(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=base_image,  # í‘ë°± ì´ë¯¸ì§€ë¥¼ ê¹Šì´ ë§µìœ¼ë¡œ ì‚¬ìš©
            num_inference_steps=30,
            controlnet_conditioning_scale=0.8,
            guidance_scale=7.5,
            width=base_image.width,
            height=base_image.height
        ).images[0]
        
        print("âœ… ControlNet 3D ë Œë”ë§ ì™„ë£Œ")
        return result
        
    except Exception as e:
        print(f"âš ï¸ ControlNet ë Œë”ë§ ì‹¤íŒ¨, ì›ë³¸ ë°˜í™˜: {e}")
        import traceback
        print(traceback.format_exc())
        return base_image

def remove_background(image: Image.Image) -> Image.Image:
    """
    ë°°ê²½ ì œê±° ë° í›„ì²˜ë¦¬ (íŒ€ì› ì½”ë“œ)
    
    1. Rembg: 1ì°¨ ë°°ê²½ ì œê±°
    2. Threshold: ì• ë§¤í•œ ë°˜íˆ¬ëª… ì°Œêº¼ê¸° ê°•ì œ ì œê±° 
    3. Erode: í…Œë‘ë¦¬ ì•ˆìª½ìœ¼ë¡œ ê¹ê¸°
    4. Blur: ê¹ì¸ ë‹¨ë©´ ë¶€ë“œëŸ½ê²Œ ì²˜ë¦¬
    """
    # 1. AI ë°°ê²½ ì œê±°
    no_bg_image = remove(
        image, 
        session=rembg_session,
        alpha_matting=True,
        alpha_matting_foreground_threshold=240,
        alpha_matting_background_threshold=10,
        alpha_matting_erode_size=5  # rembg ìì²´ erodeëŠ” ì¤„ì„
    )
    
    img_np = np.array(no_bg_image)
    
    if img_np.shape[2] == 4:
        # ì•ŒíŒŒ ì±„ë„ ë¶„ë¦¬
        alpha = img_np[:, :, 3]
        
        # ì´ì§„í™” (Thresholding)
        # íˆ¬ëª…ë„ê°€ 127(ì¤‘ê°„ê°’)ë³´ë‹¤ ë‚®ìœ¼ë©´ ì•„ì˜ˆ 0ìœ¼ë¡œ ë§Œë“ ë‹¤.
        _, binary_alpha = cv2.threshold(alpha, 127, 255, cv2.THRESH_BINARY)
        
        # ì´ì§„í™”ëœ ë§ˆìŠ¤í¬ë¥¼ ì•ˆìª½ìœ¼ë¡œ ì‚´ì§ ê¹ìŒ
        kernel = np.ones((3, 3), np.uint8)
        eroded_alpha = cv2.erode(binary_alpha, kernel, iterations=1)
        
        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ (Smoothing)
        # ë”±ë”±í•˜ê²Œ ê¹ì¸ ê²½ê³„ë©´ì„ ì•„ì£¼ ì‚´ì§ ë¶€ë“œëŸ½ê²Œ ë§Œë“¦ (ì•ˆí‹°ì•¨ë¦¬ì–´ì‹±)
        final_alpha = cv2.GaussianBlur(eroded_alpha, (3, 3), 0)
        
        # ìµœì¢… ì•ŒíŒŒ ì±„ë„ ì ìš©
        img_np[:, :, 3] = final_alpha
        
        img_np[final_alpha == 0] = 0
        
    return Image.fromarray(img_np)
