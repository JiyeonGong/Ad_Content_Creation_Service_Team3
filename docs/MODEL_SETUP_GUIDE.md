# ëª¨ë¸ ì„¤ì • ê°€ì´ë“œ

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
src/backend/
â”œâ”€â”€ model_config.yaml      # ëª¨ë¸ ì„¤ì • íŒŒì¼ (ì—¬ê¸°ë§Œ ìˆ˜ì •!)
â”œâ”€â”€ model_registry.py      # ì„¤ì • ë¡œë”
â”œâ”€â”€ model_loader.py        # ëª¨ë¸ ë¡œë”© ë¡œì§
â”œâ”€â”€ services.py            # AI ì„œë¹„ìŠ¤ ë ˆì´ì–´
â””â”€â”€ main.py                # FastAPI ì•±
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ê¸°ë³¸ ì„¤ì • (SDXL ì‚¬ìš©)

**ë³„ë„ ì„¤ì • ì—†ì´ ë°”ë¡œ ì‘ë™í•©ë‹ˆë‹¤!**

```bash
# ë°±ì—”ë“œ ì‹¤í–‰
uvicorn src.backend.main:app --host 0.0.0.0 --port 8000

# í”„ë¡ íŠ¸ì—”ë“œ ì‹¤í–‰
streamlit run src/frontend/app.py
```

ê¸°ë³¸ì ìœ¼ë¡œ `sdxl` ëª¨ë¸ì´ í´ë°±ìœ¼ë¡œ ìë™ ë¡œë“œë©ë‹ˆë‹¤.

---

### 2. FLUX ëª¨ë¸ ì‚¬ìš© (ê³ í’ˆì§ˆ)

#### 2-1. Hugging Face ì¸ì¦

```bash
pip install -U huggingface_hub
huggingface-cli login
# í† í° ì…ë ¥: https://huggingface.co/settings/tokens
```

#### 2-2. ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œ íšë“

1. https://huggingface.co/black-forest-labs/FLUX.1-schnell ë°©ë¬¸
2. "Agree and access repository" í´ë¦­

#### 2-3. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ì„ íƒ)

`.env` íŒŒì¼ ìƒì„±:

```bash
PRIMARY_MODEL=flux-schnell
ENABLE_FALLBACK=true
```

ë˜ëŠ” `model_config.yaml`ì—ì„œ `runtime.primary_model` ìˆ˜ì •

---

## ğŸ”§ ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€í•˜ê¸°

### ì˜ˆì‹œ: Stable Diffusion 3 ì¶”ê°€

`model_config.yaml`ì— ì¶”ê°€:

```yaml
models:
  sd3-medium:
    id: "stabilityai/stable-diffusion-3-medium-diffusers"
    type: "sd3"
    requires_auth: true  # HF ì¸ì¦ í•„ìš” ì‹œ
    params:
      default_steps: 28
      max_steps: 50
      use_negative_prompt: true
      guidance_scale: 7.0
      supports_i2i: true
      max_tokens: 77
      default_size: [1024, 1024]
      max_size: [2048, 2048]
      negative_prompt: "low quality, blurry"
    description: "SD3 Medium - í…ìŠ¤íŠ¸ ë Œë”ë§ ê°œì„ "

runtime:
  primary_model: "sd3-medium"  # ì—¬ê¸°ë§Œ ë³€ê²½!
  fallback_models:
    - "sdxl"
```

**ë! ì½”ë“œ ìˆ˜ì • ì—†ì´ ìƒˆ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥**

---

## ğŸ›ï¸ ê³ ê¸‰ ì„¤ì •

### ë©”ëª¨ë¦¬ ìµœì í™”

`model_config.yaml`ì˜ `runtime.memory` ì„¹ì…˜:

```yaml
runtime:
  memory:
    enable_cpu_offload: false    # CPU ì˜¤í”„ë¡œë“œ (ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ)
    enable_attention_slicing: true   # ì–´í…ì…˜ ìŠ¬ë¼ì´ì‹±
    enable_vae_slicing: true         # VAE ìŠ¬ë¼ì´ì‹±
    use_8bit: false                  # 8ë¹„íŠ¸ ì–‘ìí™”
```

**ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ê¶Œì¥ ì„¤ì •:**
- `use_8bit: true` â†’ ë©”ëª¨ë¦¬ 50% ì ˆì•½ (ì•½ê°„ ëŠë¦¼)
- `enable_cpu_offload: true` â†’ ë©”ëª¨ë¦¬ 70% ì ˆì•½ (ë§¤ìš° ëŠë¦¼)

---

### í”„ë¡¬í”„íŠ¸ ìµœì í™” ì„¤ì •

```yaml
runtime:
  prompt_optimization:
    enabled: true                # GPT í”„ë¡¬í”„íŠ¸ ìµœì í™”
    translate_korean: true       # í•œêµ­ì–´ ìë™ ë²ˆì—­
    max_length_by_model: true    # ëª¨ë¸ë³„ í† í° ì œí•œ ì¤€ìˆ˜
```

---

## ğŸŒ í™˜ê²½ë³€ìˆ˜ë¡œ ì˜¤ë²„ë¼ì´ë“œ

`.env` íŒŒì¼ ë˜ëŠ” ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜:

```bash
# ê¸°ë³¸ ëª¨ë¸ ì§€ì •
PRIMARY_MODEL=flux-schnell

# í´ë°± í™œì„±í™”/ë¹„í™œì„±í™”
ENABLE_FALLBACK=true

# ìºì‹œ ë””ë ‰í† ë¦¬ ë³€ê²½
HF_CACHE_DIR=/custom/path

# OpenAI API Key
OPENAI_API_KEY=sk-...
```

í™˜ê²½ë³€ìˆ˜ê°€ `model_config.yaml` ì„¤ì •ë³´ë‹¤ ìš°ì„ ë©ë‹ˆë‹¤.

---

## ğŸ“Š API ì—”ë“œí¬ì¸íŠ¸

### ëª¨ë¸ ì •ë³´ ì¡°íšŒ

```bash
curl http://localhost:8000/models
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "models": {
    "flux-schnell": {
      "id": "black-forest-labs/FLUX.1-schnell",
      "type": "flux",
      "requires_auth": true,
      "default_steps": 4,
      "max_tokens": 512,
      "supports_i2i": true
    },
    "sdxl": { ... }
  },
  "current": "sdxl",
  "primary": "flux-schnell",
  "fallback_chain": ["sdxl", "playground"]
}
```

### ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸

```bash
curl http://localhost:8000/status
```

---

## ğŸ”¥ ì¶”ì²œ ëª¨ë¸

| ëª¨ë¸ | ìš©ë„ | ì¸ì¦ | ì†ë„ | í’ˆì§ˆ |
|------|------|------|------|------|
| **flux-schnell** | ì¼ë°˜ ì‚¬ìš© | âœ… í•„ìš” | âš¡ ë¹ ë¦„ | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ |
| **sdxl** | ì•ˆì •ì  | âŒ ë¶ˆí•„ìš” | ğŸ¢ ë³´í†µ | ğŸŒŸğŸŒŸğŸŒŸ |
| **playground** | ë¯¸ì  í’ˆì§ˆ | âŒ ë¶ˆí•„ìš” | ğŸ¢ ë³´í†µ | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ |
| **flux-dev** | ìµœê³  í’ˆì§ˆ | âœ… í•„ìš” | ğŸŒ ëŠë¦¼ | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ |

---

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. "ì´ë¯¸ì§€ íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"

**ì›ì¸:** ëª¨ë“  ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨

**í•´ê²°:**
```bash
# ë°±ì—”ë“œ ë¡œê·¸ í™•ì¸
# ì‹¤íŒ¨í•œ ëª¨ë¸ê³¼ ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸ í›„:

# ì˜µì…˜ A: SDXLë¡œ í´ë°± ê°•ì œ
PRIMARY_MODEL=sdxl

# ì˜µì…˜ B: ì¸ì¦ ë¬¸ì œë©´
huggingface-cli login
```

### 2. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

**í•´ê²°:**
`model_config.yaml`ì—ì„œ:
```yaml
runtime:
  memory:
    use_8bit: true
```

ë˜ëŠ” ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©: `sdxl` or `playground`

### 3. í”„ë¡¬í”„íŠ¸ ë²ˆì—­ ì•ˆë¨

**í™•ì¸:**
- `.env`ì— `OPENAI_API_KEY` ì„¤ì • ì—¬ë¶€
- `model_config.yaml`ì—ì„œ `prompt_optimization.enabled: true` í™•ì¸

---

## ğŸ“ ì»¤ìŠ¤í…€ ëª¨ë¸ íƒ€ì… ì¶”ê°€

`model_loader.py`ì˜ `_load_model_by_type` ë©”ì„œë“œ ìˆ˜ì •:

```python
elif model_type == "my_custom_type":
    from my_custom_library import CustomPipeline
    t2i = CustomPipeline.from_pretrained(model_id, **load_kwargs)
    i2i = CustomPipeline.from_pretrained(model_id, **load_kwargs)
```

---

## ğŸ¯ ê²°ë¡ 

**í•˜ë“œì½”ë”© ì œê±° ì™„ë£Œ!**
- âœ… `model_config.yaml` í•˜ë‚˜ë¡œ ëª¨ë“  ëª¨ë¸ ê´€ë¦¬
- âœ… ì½”ë“œ ìˆ˜ì • ì—†ì´ ëª¨ë¸ êµì²´
- âœ… í™˜ê²½ë³€ìˆ˜ë¡œ ë™ì  ì„¤ì •
- âœ… ìë™ í´ë°± ì²´ì¸
- âœ… ë©”ëª¨ë¦¬ ìµœì í™” í† ê¸€

**ëª¨ë¸ ì¶”ê°€ëŠ” ì´ì œ 3ë‹¨ê³„:**
1. `model_config.yaml`ì— ëª¨ë¸ ì •ë³´ ì¶”ê°€
2. `runtime.primary_model` ë³€ê²½
3. ì¬ì‹œì‘